{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> <span style=\"color:white\">Electricity Sector Data Streaming & Analysis</span></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> <span style=\"color:white\">GROUP 04</span></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Name                   | SID       | Unikey   |\n",
    "| ---------------------- | --------- | -------- |\n",
    "| Putu Eka Udiyani Putri | 550067302 | pput0940 |\n",
    "| Rengga Firmandika      | 550126632 | rfir0117 |\n",
    "| Vincentius Ansel Suppa | 550206406 | vsup0468 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> <span style=\"color:orange\">0. Configuration and Import Required Libraries</span></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick start:**\n",
    "1. Project structure:\n",
    "   \n",
    "   <pre>\n",
    "   Assignment2_Tut07_G04/\n",
    "   ├── Assignment_2.ipynb      # main notebook\n",
    "   └── requirements.txt        # list of required libraries to run the notebook\n",
    "   </pre>\n",
    "\n",
    "   Ensure your working directory is writable.\n",
    "\n",
    "2. Create venv & install exact dependencies<br/>\n",
    "   `python -m venv .venv`<br/>\n",
    "   Windows: `.\\.venv\\Scripts\\activate` | macOS/Linux: `source .venv/bin/activate`<br/>\n",
    "   `python -m pip install --upgrade pip`<br/>\n",
    "   `pip install -r requirements.txt`\n",
    "\n",
    "3. Copy `.env.template` to `.env` file, replace `your_api_key` with your actual API key. \n",
    "\n",
    "4. Run the full pipeline<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required libraries first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import paho.mqtt.client as mqtt\n",
    "import sys\n",
    "import duckdb\n",
    "from thefuzz import fuzz, process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> <span style=\"color:orange\">1. Data Retrieval</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('core_functions', True, True, '(BUILT-IN)', 'Core function library', [], 'v1.4.1', 'STATICALLY_LINKED', ''), ('icu', True, True, '(BUILT-IN)', 'Adds support for time zones and collations using the ICU library', [], 'v1.4.1', 'STATICALLY_LINKED', ''), ('json', True, True, '(BUILT-IN)', 'Adds support for JSON operations', [], 'v1.4.1', 'STATICALLY_LINKED', ''), ('parquet', True, True, '(BUILT-IN)', 'Adds support for reading and writing parquet files', [], 'v1.4.1', 'STATICALLY_LINKED', ''), ('spatial', True, True, 'C:\\\\Users\\\\Rengga\\\\.duckdb\\\\extensions\\\\v1.4.1\\\\windows_amd64\\\\spatial.duckdb_extension', 'Geospatial extension that adds support for working with spatial data and functions', [], 'a6a607f', 'REPOSITORY', 'core')]\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = \"energy_dw.duckdb\"\n",
    "\n",
    "con = duckdb.connect(DB_PATH) \n",
    "con.execute(\"INSTALL spatial\")\n",
    "con.execute(\"LOAD spatial\")\n",
    "result = con.execute(\"SELECT * FROM duckdb_extensions() WHERE installed\").fetchall()\n",
    "print(result)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "# Check first rows\n",
    "assignment1_facility_data = con.execute(\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                f.year,\n",
    "                dfa.facility_name,\n",
    "                dfu.fuel_type,\n",
    "                dfu.fuel_category,\n",
    "                dfu.is_renewable,\n",
    "                dge.latitude,\n",
    "                dge.longitude,\n",
    "                dge.state_code,\n",
    "                dge.geo_resolution\n",
    "            FROM fact_nger_facility f\n",
    "            JOIN dim_facility dfa ON dfa.facility_id=f.facility_id\n",
    "            JOIN dim_fuel dfu ON dfu.fuel_key=f.fuel_key\n",
    "            JOIN dim_geo dge ON dge.geo_id=f.geo_id\n",
    "            WHERE f.grid='NEM'\n",
    "            AND f.year=2023\n",
    "        \"\"\").fetchdf()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state_code</th>\n",
       "      <th>geo_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Hallett (Stage 2) Wind Farm</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-30.534367</td>\n",
       "      <td>135.630121</td>\n",
       "      <td>SA</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Broadwater Power Plant</td>\n",
       "      <td>Wood</td>\n",
       "      <td>BIO</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>The DPESS Trust</td>\n",
       "      <td>Battery</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>False</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Moranbah North CMM Power Station</td>\n",
       "      <td>Waste Coal Mine Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Crookwell 3 Windfarm</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2023</td>\n",
       "      <td>Portland Wind Farms</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-36.598610</td>\n",
       "      <td>144.678005</td>\n",
       "      <td>VIC</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2023</td>\n",
       "      <td>Clarke Creek Wind Farm</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2023</td>\n",
       "      <td>Numurkah Project Pty Ltd</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-36.598610</td>\n",
       "      <td>144.678005</td>\n",
       "      <td>VIC</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2023</td>\n",
       "      <td>Suntop Solar Farm</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2023</td>\n",
       "      <td>Wandoan Solar Farm 1</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                     facility_name            fuel_type  \\\n",
       "0    2023       Hallett (Stage 2) Wind Farm                 Wind   \n",
       "1    2023            Broadwater Power Plant                 Wood   \n",
       "2    2023                   The DPESS Trust              Battery   \n",
       "3    2023  Moranbah North CMM Power Station  Waste Coal Mine Gas   \n",
       "4    2023              Crookwell 3 Windfarm                 Wind   \n",
       "..    ...                               ...                  ...   \n",
       "304  2023               Portland Wind Farms                 Wind   \n",
       "305  2023            Clarke Creek Wind Farm                 Wind   \n",
       "306  2023          Numurkah Project Pty Ltd                Solar   \n",
       "307  2023                 Suntop Solar Farm                Solar   \n",
       "308  2023              Wandoan Solar Farm 1                Solar   \n",
       "\n",
       "    fuel_category  is_renewable   latitude   longitude state_code  \\\n",
       "0            WIND          True -30.534367  135.630121         SA   \n",
       "1             BIO          True -31.875984  147.286949        NSW   \n",
       "2         STORAGE         False -31.875984  147.286949        NSW   \n",
       "3             GAS         False -22.164678  144.584490        QLD   \n",
       "4            WIND          True -31.875984  147.286949        NSW   \n",
       "..            ...           ...        ...         ...        ...   \n",
       "304          WIND          True -36.598610  144.678005        VIC   \n",
       "305          WIND          True -22.164678  144.584490        QLD   \n",
       "306         SOLAR          True -36.598610  144.678005        VIC   \n",
       "307         SOLAR          True -31.875984  147.286949        NSW   \n",
       "308         SOLAR          True -22.164678  144.584490        QLD   \n",
       "\n",
       "    geo_resolution  \n",
       "0            state  \n",
       "1            state  \n",
       "2            state  \n",
       "3            state  \n",
       "4            state  \n",
       "..             ...  \n",
       "304          state  \n",
       "305          state  \n",
       "306          state  \n",
       "307          state  \n",
       "308          state  \n",
       "\n",
       "[309 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment1_facility_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic configs\n",
    "API_KEY = os.getenv(\"OPENELECTRICITY_API_KEY\")\n",
    "API_KEY = API_KEY.strip().strip('\"').strip(\"'\")  \n",
    "BASE_URL = \"https://api.openelectricity.org.au/v4/\"\n",
    "HEADERS = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "\n",
    "# function to fetch data\n",
    "def fetch_data_from_API(endpoint: str, query_params: dict): \n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}{endpoint}\", headers=HEADERS, params=query_params)\n",
    "        \n",
    "        print(f\"Response status: {response.status_code}\")\n",
    "        print(f\"Response url: {response.url}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"API Error {response.status_code}: {response.text}\")\n",
    "            print(f\"Response headers: {dict(response.headers)}\")\n",
    "\n",
    "            try:\n",
    "                error_json = response.json()\n",
    "                print(f\"Error details: {error_json}\")\n",
    "            except:\n",
    "                print(\"Could not parse error response as JSON\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# helper function to save dataset\n",
    "def save_dataset(df: pd.DataFrame, out_csv_path: str):\n",
    "\tout_path = Path(out_csv_path)\n",
    "\tout_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\tdf.to_csv(out_path, index=False)\n",
    "\tprint(f\"Saved: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> <span style=\"color:pink\">1.1 Get All Facilities in NEM Region</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status: 200\n",
      "Response url: https://api.openelectricity.org.au/v4/facilities/?network_id=NEM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>network_id</th>\n",
       "      <th>network_region</th>\n",
       "      <th>description</th>\n",
       "      <th>units</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>created_at</th>\n",
       "      <th>location.lat</th>\n",
       "      <th>location.lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>Adelaide Desalination</td>\n",
       "      <td>NEM</td>\n",
       "      <td>SA1</td>\n",
       "      <td>&lt;p&gt;The Adelaide Desalination plant (ADP), form...</td>\n",
       "      <td>[{'code': 'ADPPV1', 'fueltech_id': 'solar_util...</td>\n",
       "      <td>2025-08-05T06:08:12Z</td>\n",
       "      <td>2023-10-18T04:34:30Z</td>\n",
       "      <td>-35.096948</td>\n",
       "      <td>138.484061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDGASF</td>\n",
       "      <td>Aldoga</td>\n",
       "      <td>NEM</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>&lt;p&gt;The Aldoga Solar Farm will be approximately...</td>\n",
       "      <td>[{'code': 'ALDGASF1', 'fueltech_id': 'solar_ut...</td>\n",
       "      <td>2025-03-25T00:52:44Z</td>\n",
       "      <td>2025-01-31T04:19:33Z</td>\n",
       "      <td>-23.839544</td>\n",
       "      <td>151.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMCORGR</td>\n",
       "      <td>Amcor Glass</td>\n",
       "      <td>NEM</td>\n",
       "      <td>SA1</td>\n",
       "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
       "      <td>[{'code': 'AMCORGR', 'fueltech_id': 'distillat...</td>\n",
       "      <td>2023-10-18T04:34:32Z</td>\n",
       "      <td>2023-10-18T04:34:32Z</td>\n",
       "      <td>-34.882663</td>\n",
       "      <td>138.577975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANGASTON</td>\n",
       "      <td>Angaston</td>\n",
       "      <td>NEM</td>\n",
       "      <td>SA1</td>\n",
       "      <td>&lt;p&gt;Angaston Power Station is a diesel-powered ...</td>\n",
       "      <td>[{'code': 'ANGAS1', 'fueltech_id': 'distillate...</td>\n",
       "      <td>2025-09-07T01:53:13Z</td>\n",
       "      <td>2023-10-18T04:34:32Z</td>\n",
       "      <td>-34.503948</td>\n",
       "      <td>139.024296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APS</td>\n",
       "      <td>Anglesea</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>&lt;p&gt;The Anglesea Power Station was a brown coal...</td>\n",
       "      <td>[{'code': 'APS', 'fueltech_id': 'coal_brown', ...</td>\n",
       "      <td>2024-11-04T00:41:34Z</td>\n",
       "      <td>2023-10-18T04:34:32Z</td>\n",
       "      <td>-38.389031</td>\n",
       "      <td>144.180589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                   name network_id network_region  \\\n",
       "0       ADP  Adelaide Desalination        NEM            SA1   \n",
       "1   ALDGASF                 Aldoga        NEM           QLD1   \n",
       "2   AMCORGR            Amcor Glass        NEM            SA1   \n",
       "3  ANGASTON               Angaston        NEM            SA1   \n",
       "4       APS               Anglesea        NEM           VIC1   \n",
       "\n",
       "                                         description  \\\n",
       "0  <p>The Adelaide Desalination plant (ADP), form...   \n",
       "1  <p>The Aldoga Solar Farm will be approximately...   \n",
       "2                                            <p></p>   \n",
       "3  <p>Angaston Power Station is a diesel-powered ...   \n",
       "4  <p>The Anglesea Power Station was a brown coal...   \n",
       "\n",
       "                                               units            updated_at  \\\n",
       "0  [{'code': 'ADPPV1', 'fueltech_id': 'solar_util...  2025-08-05T06:08:12Z   \n",
       "1  [{'code': 'ALDGASF1', 'fueltech_id': 'solar_ut...  2025-03-25T00:52:44Z   \n",
       "2  [{'code': 'AMCORGR', 'fueltech_id': 'distillat...  2023-10-18T04:34:32Z   \n",
       "3  [{'code': 'ANGAS1', 'fueltech_id': 'distillate...  2025-09-07T01:53:13Z   \n",
       "4  [{'code': 'APS', 'fueltech_id': 'coal_brown', ...  2024-11-04T00:41:34Z   \n",
       "\n",
       "             created_at  location.lat  location.lng  \n",
       "0  2023-10-18T04:34:30Z    -35.096948    138.484061  \n",
       "1  2025-01-31T04:19:33Z    -23.839544    151.084900  \n",
       "2  2023-10-18T04:34:32Z    -34.882663    138.577975  \n",
       "3  2023-10-18T04:34:32Z    -34.503948    139.024296  \n",
       "4  2023-10-18T04:34:32Z    -38.389031    144.180589  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set endpoint and params\n",
    "ENDPOINT = \"facilities/\"\n",
    "PARAMS = {\n",
    "    'network_id': 'NEM',\n",
    "}\n",
    "\n",
    "# fetch facilities data\n",
    "facilities = fetch_data_from_API(endpoint=ENDPOINT, query_params=PARAMS)\n",
    "facilities_df = pd.json_normalize(facilities['data'])\n",
    "facilities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_code = facilities_df.set_index('name')['code'].to_dict()\n",
    "\n",
    "def get_best_match(facility_name, choices, threshold=80):\n",
    "    \"\"\"Find best matching name and return its code\"\"\"\n",
    "    result = process.extractOne(facility_name, choices, scorer=fuzz.token_sort_ratio)\n",
    "    if result and result[1] >= threshold:  # result[1] is the score\n",
    "        return name_to_code[result[0]]\n",
    "    return None\n",
    "\n",
    "# Apply fuzzy matching\n",
    "assignment1_facility_data['code'] = assignment1_facility_data['facility_name'].apply(\n",
    "    lambda x: get_best_match(x, name_to_code.keys(), threshold=60)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state_code</th>\n",
       "      <th>geo_resolution</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Broadwater Power Plant</td>\n",
       "      <td>Wood</td>\n",
       "      <td>BIO</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "      <td>BWTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Moranbah North CMM Power Station</td>\n",
       "      <td>Waste Coal Mine Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "      <td>MBAHNTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Crookwell 3 Windfarm</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "      <td>CROOKWF3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>Metz Solar Farm</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "      <td>OAKEY1SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023</td>\n",
       "      <td>PARKES SOLAR FARM PTY LTD</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "      <td>OAKEY1SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2023</td>\n",
       "      <td>MOURA SOLAR FARM SPV PTY LTD</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "      <td>OAKEY1SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2023</td>\n",
       "      <td>Portland Wind Farms</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-36.598610</td>\n",
       "      <td>144.678005</td>\n",
       "      <td>VIC</td>\n",
       "      <td>state</td>\n",
       "      <td>WRWF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2023</td>\n",
       "      <td>Clarke Creek Wind Farm</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "      <td>CLRKCWF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2023</td>\n",
       "      <td>Suntop Solar Farm</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>state</td>\n",
       "      <td>WRSF1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2023</td>\n",
       "      <td>Wandoan Solar Farm 1</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>state</td>\n",
       "      <td>WANDBG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year                     facility_name            fuel_type  \\\n",
       "1    2023            Broadwater Power Plant                 Wood   \n",
       "3    2023  Moranbah North CMM Power Station  Waste Coal Mine Gas   \n",
       "4    2023              Crookwell 3 Windfarm                 Wind   \n",
       "9    2023                   Metz Solar Farm                Solar   \n",
       "10   2023         PARKES SOLAR FARM PTY LTD                Solar   \n",
       "..    ...                               ...                  ...   \n",
       "302  2023      MOURA SOLAR FARM SPV PTY LTD                Solar   \n",
       "304  2023               Portland Wind Farms                 Wind   \n",
       "305  2023            Clarke Creek Wind Farm                 Wind   \n",
       "307  2023                 Suntop Solar Farm                Solar   \n",
       "308  2023              Wandoan Solar Farm 1                Solar   \n",
       "\n",
       "    fuel_category  is_renewable   latitude   longitude state_code  \\\n",
       "1             BIO          True -31.875984  147.286949        NSW   \n",
       "3             GAS         False -22.164678  144.584490        QLD   \n",
       "4            WIND          True -31.875984  147.286949        NSW   \n",
       "9           SOLAR          True -31.875984  147.286949        NSW   \n",
       "10          SOLAR          True -31.875984  147.286949        NSW   \n",
       "..            ...           ...        ...         ...        ...   \n",
       "302         SOLAR          True -22.164678  144.584490        QLD   \n",
       "304          WIND          True -36.598610  144.678005        VIC   \n",
       "305          WIND          True -22.164678  144.584490        QLD   \n",
       "307         SOLAR          True -31.875984  147.286949        NSW   \n",
       "308         SOLAR          True -22.164678  144.584490        QLD   \n",
       "\n",
       "    geo_resolution      code  \n",
       "1            state     BWTR1  \n",
       "3            state   MBAHNTH  \n",
       "4            state  CROOKWF3  \n",
       "9            state  OAKEY1SF  \n",
       "10           state  OAKEY1SF  \n",
       "..             ...       ...  \n",
       "302          state  OAKEY1SF  \n",
       "304          state     WRWF1  \n",
       "305          state   CLRKCWF  \n",
       "307          state     WRSF1  \n",
       "308          state    WANDBG  \n",
       "\n",
       "[136 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment1_facility_data[assignment1_facility_data['code'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "                  name\n",
      "0      dim_corporation\n",
      "1         dim_facility\n",
      "2             dim_fuel\n",
      "3              dim_geo\n",
      "4         dim_industry\n",
      "5            dim_stage\n",
      "6    fact_abs_industry\n",
      "7  fact_abs_population\n",
      "8     fact_cer_project\n",
      "9   fact_nger_facility\n",
      "\n",
      "Preview of table 'fact_nger_facility':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_id</th>\n",
       "      <th>year</th>\n",
       "      <th>corporation_id</th>\n",
       "      <th>fuel_key</th>\n",
       "      <th>electricity_gj</th>\n",
       "      <th>electricity_mwh</th>\n",
       "      <th>emissions_1</th>\n",
       "      <th>emissions_2</th>\n",
       "      <th>emissions_total</th>\n",
       "      <th>emissions_intensity</th>\n",
       "      <th>grid_connected</th>\n",
       "      <th>grid</th>\n",
       "      <th>geo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>567719.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>NEM</td>\n",
       "      <td>2316593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>567719.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>NEM</td>\n",
       "      <td>2316593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>567719.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>NEM</td>\n",
       "      <td>2316593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>567719.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>NEM</td>\n",
       "      <td>2316593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>567719.0</td>\n",
       "      <td>157700.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ON</td>\n",
       "      <td>NEM</td>\n",
       "      <td>2316593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   facility_id  year  corporation_id  fuel_key  electricity_gj  \\\n",
       "0            1  2014               1         1        567719.0   \n",
       "1            1  2014               1         1        567719.0   \n",
       "2            1  2014               1         1        567719.0   \n",
       "3            1  2014               1         1        567719.0   \n",
       "4            1  2014               1         1        567719.0   \n",
       "\n",
       "   electricity_mwh  emissions_1  emissions_2  emissions_total  \\\n",
       "0         157700.0         19.0        293.0              312   \n",
       "1         157700.0         19.0        293.0              312   \n",
       "2         157700.0         19.0        293.0              312   \n",
       "3         157700.0         19.0        293.0              312   \n",
       "4         157700.0         19.0        293.0              312   \n",
       "\n",
       "   emissions_intensity grid_connected grid   geo_id  \n",
       "0                  0.0             ON  NEM  2316593  \n",
       "1                  0.0             ON  NEM  2316593  \n",
       "2                  0.0             ON  NEM  2316593  \n",
       "3                  0.0             ON  NEM  2316593  \n",
       "4                  0.0             ON  NEM  2316593  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of table 'dim_facility':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_id</th>\n",
       "      <th>facility_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gunning Wind Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Royalla Solar Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Waubra Wind Farm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Banimboola Hydro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bayswater Power Station</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   facility_id            facility_name\n",
       "0            1        Gunning Wind Farm\n",
       "1            2       Royalla Solar Farm\n",
       "2            3         Waubra Wind Farm\n",
       "3            4         Banimboola Hydro\n",
       "4            5  Bayswater Power Station"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of table 'dim_geo':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state_code</th>\n",
       "      <th>display_name</th>\n",
       "      <th>postcode</th>\n",
       "      <th>min_lat</th>\n",
       "      <th>max_lat</th>\n",
       "      <th>min_lon</th>\n",
       "      <th>max_lon</th>\n",
       "      <th>geo_resolution</th>\n",
       "      <th>osm_type</th>\n",
       "      <th>geocoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289547296</td>\n",
       "      <td>-20.729005</td>\n",
       "      <td>139.493224</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Mount Isa Post Office, Isa Street, Mount Isa C...</td>\n",
       "      <td>4825.0</td>\n",
       "      <td>-20.729055</td>\n",
       "      <td>-20.728955</td>\n",
       "      <td>139.493174</td>\n",
       "      <td>139.493274</td>\n",
       "      <td>postcode</td>\n",
       "      <td>node</td>\n",
       "      <td>nominatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5519705</td>\n",
       "      <td>-33.965003</td>\n",
       "      <td>150.801103</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Leppington, Sydney, Camden Council, New South ...</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>-34.004331</td>\n",
       "      <td>-33.948324</td>\n",
       "      <td>150.759408</td>\n",
       "      <td>150.841382</td>\n",
       "      <td>exact</td>\n",
       "      <td>relation</td>\n",
       "      <td>nominatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2918464324</td>\n",
       "      <td>-33.719717</td>\n",
       "      <td>150.892220</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Quakers Hillside Care Community, Hambledon Rd,...</td>\n",
       "      <td>2763.0</td>\n",
       "      <td>-33.719767</td>\n",
       "      <td>-33.719667</td>\n",
       "      <td>150.892170</td>\n",
       "      <td>150.892270</td>\n",
       "      <td>exact</td>\n",
       "      <td>node</td>\n",
       "      <td>nominatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22963243</td>\n",
       "      <td>-37.817580</td>\n",
       "      <td>144.969976</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Ian Potter Centre: NGV Australia, Russell Stre...</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>-37.818067</td>\n",
       "      <td>-37.817012</td>\n",
       "      <td>144.969603</td>\n",
       "      <td>144.970339</td>\n",
       "      <td>postcode</td>\n",
       "      <td>way</td>\n",
       "      <td>nominatim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15268146</td>\n",
       "      <td>-27.541981</td>\n",
       "      <td>153.079185</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Hillsong Brisbane Campus, 16, Rover Street, Mo...</td>\n",
       "      <td>4074.0</td>\n",
       "      <td>-27.542259</td>\n",
       "      <td>-27.541120</td>\n",
       "      <td>153.078875</td>\n",
       "      <td>153.079691</td>\n",
       "      <td>postcode</td>\n",
       "      <td>relation</td>\n",
       "      <td>nominatim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_id   latitude   longitude state_code  \\\n",
       "0   289547296 -20.729005  139.493224        QLD   \n",
       "1     5519705 -33.965003  150.801103        NSW   \n",
       "2  2918464324 -33.719717  150.892220        NSW   \n",
       "3    22963243 -37.817580  144.969976        VIC   \n",
       "4    15268146 -27.541981  153.079185        QLD   \n",
       "\n",
       "                                        display_name  postcode    min_lat  \\\n",
       "0  Mount Isa Post Office, Isa Street, Mount Isa C...    4825.0 -20.729055   \n",
       "1  Leppington, Sydney, Camden Council, New South ...    2179.0 -34.004331   \n",
       "2  Quakers Hillside Care Community, Hambledon Rd,...    2763.0 -33.719767   \n",
       "3  Ian Potter Centre: NGV Australia, Russell Stre...    3008.0 -37.818067   \n",
       "4  Hillsong Brisbane Campus, 16, Rover Street, Mo...    4074.0 -27.542259   \n",
       "\n",
       "     max_lat     min_lon     max_lon geo_resolution  osm_type   geocoder  \n",
       "0 -20.728955  139.493174  139.493274       postcode      node  nominatim  \n",
       "1 -33.948324  150.759408  150.841382          exact  relation  nominatim  \n",
       "2 -33.719667  150.892170  150.892270          exact      node  nominatim  \n",
       "3 -37.817012  144.969603  144.970339       postcode       way  nominatim  \n",
       "4 -27.541120  153.078875  153.079691       postcode  relation  nominatim  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of table 'dim_fuel':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fuel_key</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Solar</td>\n",
       "      <td>SOLAR</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>HYDRO</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Black Coal</td>\n",
       "      <td>COAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fuel_key   fuel_type fuel_category  is_renewable\n",
       "0         1        Wind          WIND          True\n",
       "1         2       Solar         SOLAR          True\n",
       "2         3       Hydro         HYDRO          True\n",
       "3         4  Black Coal          COAL         False\n",
       "4         5         Gas           GAS         False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 0 - Trial - Eka\n",
    "\n",
    "import duckdb, pandas as pd\n",
    "\n",
    "# connect to the DuckDB database created in Assignment 1\n",
    "con = duckdb.connect(\"energy_dw.duckdb\", read_only=True)\n",
    "\n",
    "print(\"Tables in the database:\")\n",
    "print(con.execute(\"SHOW TABLES;\").df())\n",
    "\n",
    "# peek likely facility tables to understand the schema\n",
    "for t in [\"fact_nger_facility\", \"dim_facility\", \"dim_geo\", \"dim_fuel\"]:\n",
    "    try:\n",
    "        print(f\"\\nPreview of table '{t}':\")\n",
    "        display(con.execute(f\"SELECT * FROM {t} LIMIT 5\").df())\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facility master from DB: (692, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_code</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "      <td>Chinchilla BESS</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Battery</td>\n",
       "      <td>STORAGE</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>Broadwater Power Plant</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Wood</td>\n",
       "      <td>BIO</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>Condong Power Plant</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Wood</td>\n",
       "      <td>BIO</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>The Drop Hydro</td>\n",
       "      <td>-31.875984</td>\n",
       "      <td>147.286949</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>HYDRO</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>514</td>\n",
       "      <td>Yaloak South Wind Farm</td>\n",
       "      <td>-36.598610</td>\n",
       "      <td>144.678005</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Wind</td>\n",
       "      <td>WIND</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   facility_code           facility_name   latitude   longitude region  \\\n",
       "0            791         Chinchilla BESS -22.164678  144.584490    QLD   \n",
       "1             63  Broadwater Power Plant -31.875984  147.286949    NSW   \n",
       "2             64     Condong Power Plant -31.875984  147.286949    NSW   \n",
       "3            212          The Drop Hydro -31.875984  147.286949    NSW   \n",
       "4            514  Yaloak South Wind Farm -36.598610  144.678005    VIC   \n",
       "\n",
       "  fuel_type fuel_category  is_renewable  \n",
       "0   Battery       STORAGE         False  \n",
       "1      Wood           BIO          True  \n",
       "2      Wood           BIO          True  \n",
       "3     Hydro         HYDRO          True  \n",
       "4      Wind          WIND          True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull both sources (from DB and from API) - Trial - Eka\n",
    "\n",
    "# Pull facility master directly from DuckDB (joined dimensions)\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    f.facility_id        AS facility_code,\n",
    "    d.facility_name,\n",
    "    g.latitude,\n",
    "    g.longitude,\n",
    "    g.state_code         AS region,\n",
    "    fuel.fuel_type,\n",
    "    fuel.fuel_category,\n",
    "    fuel.is_renewable\n",
    "FROM fact_nger_facility AS f\n",
    "LEFT JOIN dim_facility AS d ON f.facility_id = d.facility_id\n",
    "LEFT JOIN dim_geo      AS g ON f.geo_id      = g.geo_id\n",
    "LEFT JOIN dim_fuel     AS fuel ON f.fuel_key = fuel.fuel_key\n",
    "WHERE g.latitude IS NOT NULL\n",
    "GROUP BY 1,2,3,4,5,6,7,8\n",
    "\"\"\"\n",
    "\n",
    "facility_master = con.execute(query).df()\n",
    "print(\"Facility master from DB:\", facility_master.shape)\n",
    "facility_master.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API facilities: (514, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facility_code</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>region_api</th>\n",
       "      <th>lat_api</th>\n",
       "      <th>lng_api</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>Adelaide Desalination</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-35.096948</td>\n",
       "      <td>138.484061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDGASF</td>\n",
       "      <td>Aldoga</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-23.839544</td>\n",
       "      <td>151.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMCORGR</td>\n",
       "      <td>Amcor Glass</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.882663</td>\n",
       "      <td>138.577975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANGASTON</td>\n",
       "      <td>Angaston</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.503948</td>\n",
       "      <td>139.024296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APS</td>\n",
       "      <td>Anglesea</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-38.389031</td>\n",
       "      <td>144.180589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  facility_code          facility_name region_api    lat_api     lng_api\n",
       "0           ADP  Adelaide Desalination        SA1 -35.096948  138.484061\n",
       "1       ALDGASF                 Aldoga       QLD1 -23.839544  151.084900\n",
       "2       AMCORGR            Amcor Glass        SA1 -34.882663  138.577975\n",
       "3      ANGASTON               Angaston        SA1 -34.503948  139.024296\n",
       "4           APS               Anglesea       VIC1 -38.389031  144.180589"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a clean API dataframe for matching - Trial - Eka\n",
    "facilities_api = facilities_df.rename(columns={\n",
    "    \"code\": \"facility_code\",\n",
    "    \"name\": \"facility_name\",\n",
    "    \"location.lat\": \"lat_api\",\n",
    "    \"location.lng\": \"lng_api\",\n",
    "    \"network_region\": \"region_api\",\n",
    "})[[\"facility_code\",\"facility_name\",\"region_api\",\"lat_api\",\"lng_api\"]]\n",
    "\n",
    "print(\"API facilities:\", facilities_api.shape)\n",
    "facilities_api.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API rows: 514 | DB rows: 495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  facility_code          facility_name region_api    lat_api     lng_api  \\\n",
       " 0           ADP  Adelaide Desalination        SA1 -35.096948  138.484061   \n",
       " 1       ALDGASF                 Aldoga       QLD1 -23.839544  151.084900   \n",
       " 2       AMCORGR            Amcor Glass        SA1 -34.882663  138.577975   \n",
       " \n",
       "                name_norm  \n",
       " 0  adelaide desalination  \n",
       " 1                 aldoga  \n",
       " 2            amcor glass  ,\n",
       "    facility_code           facility_name   latitude   longitude region  \\\n",
       " 0            791         Chinchilla BESS -22.164678  144.584490    QLD   \n",
       " 1             63  Broadwater Power Plant -31.875984  147.286949    NSW   \n",
       " 2             64     Condong Power Plant -31.875984  147.286949    NSW   \n",
       " \n",
       "   fuel_type fuel_category  is_renewable         name_norm region_db  \n",
       " 0   Battery       STORAGE         False   chinchilla bess      QLD1  \n",
       " 1      Wood           BIO          True  broadwater power      NSW1  \n",
       " 2      Wood           BIO          True     condong power      NSW1  )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another match by facility_code - Trial - Eka\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def normalise_name(s: str) -> str:\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\b(p/l|pty|ltd|limited|power\\s*station|pp|plant|facility|unit|station|co|company)\\b\", \" \", s)\n",
    "    s = re.sub(r\"[\\(\\)\\[\\]\\.,/\\\\\\-_'’]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# 4a) API: normalised name\n",
    "api2 = facilities_api.copy()\n",
    "api2[\"name_norm\"]   = api2[\"facility_name\"].apply(normalise_name)\n",
    "api2[\"region_api\"]  = api2[\"region_api\"].astype(str).str.upper().str.strip()\n",
    "\n",
    "# 4b) DB: normalised name + map state_code -> NEM region code (NSW->NSW1, dll.)\n",
    "REGION_MAP = {\"NSW\":\"NSW1\",\"VIC\":\"VIC1\",\"QLD\":\"QLD1\",\"SA\":\"SA1\",\"TAS\":\"TAS1\"}\n",
    "db2 = facility_master.copy()\n",
    "db2[\"name_norm\"]    = db2[\"facility_name\"].apply(normalise_name)\n",
    "db2[\"region_db\"]    = db2[\"region\"].astype(str).str.upper().str.strip().map(REGION_MAP)\n",
    "\n",
    "# (opsional) buang yang di luar NEM (region_db NaN)\n",
    "db2 = db2[~db2[\"region_db\"].isna()].copy()\n",
    "\n",
    "print(\"API rows:\", len(api2), \"| DB rows:\", len(db2))\n",
    "api2.head(3), db2.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched by name+region in this attempt: 23\n",
      "Unmatched after name+region in this attempt: 492\n",
      "[Attempt 1: exact name+region] total rows: 514\n",
      "[Attempt 1: exact name+region] matched rows: 22\n",
      "[Attempt 1: exact name+region] remaining unmatched: 492\n",
      "[Attempt 1: exact name+region] progress: 4.28%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_code_api</th>\n",
       "      <th>facility_name_api</th>\n",
       "      <th>region_api</th>\n",
       "      <th>lat_api</th>\n",
       "      <th>lng_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>matched_facility_id</th>\n",
       "      <th>match_strategy</th>\n",
       "      <th>facility_code_db</th>\n",
       "      <th>facility_name_db</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "      <th>region_db</th>\n",
       "      <th>__chosen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>BARCALDN</td>\n",
       "      <td>Barcaldine</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-23.552171</td>\n",
       "      <td>145.314851</td>\n",
       "      <td>barcaldine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>Barcaldine Power Station Facility</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>BARCSF</td>\n",
       "      <td>Barcaldine</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-23.547333</td>\n",
       "      <td>145.318972</td>\n",
       "      <td>barcaldine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "      <td>Barcaldine Power Station Facility</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>BARRON</td>\n",
       "      <td>Barron Gorge</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-16.850770</td>\n",
       "      <td>145.647049</td>\n",
       "      <td>barron gorge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325.0</td>\n",
       "      <td>Barron Gorge Power Station</td>\n",
       "      <td>-22.164678</td>\n",
       "      <td>144.584490</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Hydro</td>\n",
       "      <td>HYDRO</td>\n",
       "      <td>True</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>BOLIVAR</td>\n",
       "      <td>Bolivar</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.495482</td>\n",
       "      <td>138.387641</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757.0</td>\n",
       "      <td>Bolivar Power Station</td>\n",
       "      <td>-30.534367</td>\n",
       "      <td>135.630121</td>\n",
       "      <td>SA</td>\n",
       "      <td>Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>SA1</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>BOLIVPS</td>\n",
       "      <td>Bolivar</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.777200</td>\n",
       "      <td>138.582600</td>\n",
       "      <td>bolivar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>757.0</td>\n",
       "      <td>Bolivar Power Station</td>\n",
       "      <td>-30.534367</td>\n",
       "      <td>135.630121</td>\n",
       "      <td>SA</td>\n",
       "      <td>Gas</td>\n",
       "      <td>GAS</td>\n",
       "      <td>False</td>\n",
       "      <td>SA1</td>\n",
       "      <td>757.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_api facility_code_api facility_name_api region_api    lat_api  \\\n",
       "18         18          BARCALDN        Barcaldine       QLD1 -23.552171   \n",
       "19         19            BARCSF        Barcaldine       QLD1 -23.547333   \n",
       "21         21            BARRON      Barron Gorge       QLD1 -16.850770   \n",
       "39         39           BOLIVAR           Bolivar        SA1 -34.495482   \n",
       "40         40           BOLIVPS           Bolivar        SA1 -34.777200   \n",
       "\n",
       "       lng_api     name_norm matched_facility_id match_strategy  \\\n",
       "18  145.314851    barcaldine                 NaN            NaN   \n",
       "19  145.318972    barcaldine                 NaN            NaN   \n",
       "21  145.647049  barron gorge                 NaN            NaN   \n",
       "39  138.387641       bolivar                 NaN            NaN   \n",
       "40  138.582600       bolivar                 NaN            NaN   \n",
       "\n",
       "    facility_code_db                   facility_name_db   latitude  \\\n",
       "18             447.0  Barcaldine Power Station Facility -22.164678   \n",
       "19             447.0  Barcaldine Power Station Facility -22.164678   \n",
       "21             325.0         Barron Gorge Power Station -22.164678   \n",
       "39             757.0              Bolivar Power Station -30.534367   \n",
       "40             757.0              Bolivar Power Station -30.534367   \n",
       "\n",
       "     longitude region fuel_type fuel_category is_renewable region_db  \\\n",
       "18  144.584490    QLD       Gas           GAS        False      QLD1   \n",
       "19  144.584490    QLD       Gas           GAS        False      QLD1   \n",
       "21  144.584490    QLD     Hydro         HYDRO         True      QLD1   \n",
       "39  135.630121     SA       Gas           GAS        False       SA1   \n",
       "40  135.630121     SA       Gas           GAS        False       SA1   \n",
       "\n",
       "   __chosen_id  \n",
       "18       447.0  \n",
       "19       447.0  \n",
       "21       325.0  \n",
       "39       757.0  \n",
       "40       757.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_code_api</th>\n",
       "      <th>facility_name_api</th>\n",
       "      <th>region_api</th>\n",
       "      <th>lat_api</th>\n",
       "      <th>lng_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>matched_facility_id</th>\n",
       "      <th>match_strategy</th>\n",
       "      <th>facility_code_db</th>\n",
       "      <th>facility_name_db</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_category</th>\n",
       "      <th>is_renewable</th>\n",
       "      <th>region_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Adelaide Desalination</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-35.096948</td>\n",
       "      <td>138.484061</td>\n",
       "      <td>adelaide desalination</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALDGASF</td>\n",
       "      <td>Aldoga</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-23.839544</td>\n",
       "      <td>151.084900</td>\n",
       "      <td>aldoga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AMCORGR</td>\n",
       "      <td>Amcor Glass</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.882663</td>\n",
       "      <td>138.577975</td>\n",
       "      <td>amcor glass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ANGASTON</td>\n",
       "      <td>Angaston</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-34.503948</td>\n",
       "      <td>139.024296</td>\n",
       "      <td>angaston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>APS</td>\n",
       "      <td>Anglesea</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-38.389031</td>\n",
       "      <td>144.180589</td>\n",
       "      <td>anglesea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api facility_code_api      facility_name_api region_api    lat_api  \\\n",
       "0          0               ADP  Adelaide Desalination        SA1 -35.096948   \n",
       "1          1           ALDGASF                 Aldoga       QLD1 -23.839544   \n",
       "2          2           AMCORGR            Amcor Glass        SA1 -34.882663   \n",
       "3          3          ANGASTON               Angaston        SA1 -34.503948   \n",
       "4          4               APS               Anglesea       VIC1 -38.389031   \n",
       "\n",
       "      lng_api              name_norm matched_facility_id match_strategy  \\\n",
       "0  138.484061  adelaide desalination                 NaN            NaN   \n",
       "1  151.084900                 aldoga                 NaN            NaN   \n",
       "2  138.577975            amcor glass                 NaN            NaN   \n",
       "3  139.024296               angaston                 NaN            NaN   \n",
       "4  144.180589               anglesea                 NaN            NaN   \n",
       "\n",
       "   facility_code_db facility_name_db  latitude  longitude region fuel_type  \\\n",
       "0               NaN              NaN       NaN        NaN    NaN       NaN   \n",
       "1               NaN              NaN       NaN        NaN    NaN       NaN   \n",
       "2               NaN              NaN       NaN        NaN    NaN       NaN   \n",
       "3               NaN              NaN       NaN        NaN    NaN       NaN   \n",
       "4               NaN              NaN       NaN        NaN    NaN       NaN   \n",
       "\n",
       "  fuel_category is_renewable region_db  \n",
       "0           NaN          NaN       NaN  \n",
       "1           NaN          NaN       NaN  \n",
       "2           NaN          NaN       NaN  \n",
       "3           NaN          NaN       NaN  \n",
       "4           NaN          NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 1: Exact match by name_norm + region, with proper progress tracking and ID fallback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure tracking columns exist on api2.\"\"\"\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    \"\"\"Print compact progress of matching status.\"\"\"\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "# Ensure tracking columns exist\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# Work only on rows not yet matched\n",
    "candidates = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "candidates = candidates.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "\n",
    "# Attempt 1: exact merge by name_norm + region\n",
    "merged_name = candidates.merge(\n",
    "    db2,\n",
    "    left_on=[\"name_norm\", \"region_api\"],\n",
    "    right_on=[\"name_norm\", \"region_db\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_api\", \"_db\")\n",
    ")\n",
    "\n",
    "# Determine which rows are matched\n",
    "# If facility_id_db exists, use it to decide; otherwise fall back to facility_name_db\n",
    "has_id_col = \"facility_id_db\" in merged_name.columns\n",
    "is_matched = merged_name[\"facility_id_db\"].notna() if has_id_col else merged_name[\"facility_name_db\"].notna()\n",
    "\n",
    "matched_name = merged_name[is_matched].copy()\n",
    "unmatched_name = merged_name[~is_matched].copy()\n",
    "\n",
    "# ---- Fallback ID selection: facility_id_db -> facility_code_db -> facility_name_db ----\n",
    "id_candidates = [c for c in [\"facility_id_db\", \"facility_code_db\", \"facility_name_db\"] if c in matched_name.columns]\n",
    "if not id_candidates:\n",
    "    # If none of the ID-like columns exist, we cannot record progress; keep informative print and skip writing\n",
    "    print(\"No ID-like columns found in db2 (facility_id_db / facility_code_db / facility_name_db).\")\n",
    "else:\n",
    "    # Build a single chosen ID column by taking first non-null across available candidates\n",
    "    matched_name[\"__chosen_id\"] = matched_name[id_candidates].bfill(axis=1).iloc[:, 0]\n",
    "    # Some rows could still be NaN if all candidates null; keep only rows with a chosen id\n",
    "    matched_name = matched_name[matched_name[\"__chosen_id\"].notna()].copy()\n",
    "\n",
    "    # Apply matches back into api2 using index_api\n",
    "    if not matched_name.empty:\n",
    "        api_idx = matched_name[\"index_api\"].values\n",
    "        api2.loc[api_idx, \"matched_facility_id\"] = matched_name[\"__chosen_id\"].astype(str).values\n",
    "        api2.loc[api_idx, \"match_strategy\"] = \"exact_name_region\"\n",
    "\n",
    "# Attempt-specific summary\n",
    "print(f\"Matched by name+region in this attempt: {len(matched_name)}\")\n",
    "print(f\"Unmatched after name+region in this attempt: {len(unmatched_name)}\")\n",
    "\n",
    "# Global cumulative progress\n",
    "_progress(api2, label=\"Attempt 1: exact name+region\")\n",
    "\n",
    "# Optional: quick peek\n",
    "display(matched_name.head(5))\n",
    "display(unmatched_name.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 2] Using 'facility_code' from db2 as the match identifier.\n",
      "Fuzzy accepted (>= 90): 256\n",
      "Fuzzy below threshold: 235\n",
      "No region choices: 1\n",
      "[Attempt 2: fuzzy name within region] total rows: 514\n",
      "[Attempt 2: fuzzy name within region] matched rows: 278\n",
      "[Attempt 2: fuzzy name within region] remaining unmatched: 236\n",
      "[Attempt 2: fuzzy name within region] progress: 54.09%\n",
      "Accepted (top 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rengga\\AppData\\Local\\Temp\\ipykernel_19628\\253743194.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: list(zip(g[\"name_norm\"].astype(str).tolist(),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>region_api</th>\n",
       "      <th>__best_name</th>\n",
       "      <th>__best_score</th>\n",
       "      <th>matched_facility_id</th>\n",
       "      <th>match_strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>adelaide desalination</td>\n",
       "      <td>SA1</td>\n",
       "      <td>appin csm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aldoga</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>avonlie solar farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>amcor glass</td>\n",
       "      <td>SA1</td>\n",
       "      <td>awaba renewable energy</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>angaston</td>\n",
       "      <td>SA1</td>\n",
       "      <td>bango wind farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>ararat</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>beryl solar farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>avonlie</td>\n",
       "      <td>NSW1</td>\n",
       "      <td>newtricity developments biala</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>awaba</td>\n",
       "      <td>NSW1</td>\n",
       "      <td>blayney wind farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>baking board</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>boco rock wind farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>bald hills</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>bodangora wind farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>ballarat</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>bomen solar farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_api              name_norm region_api  \\\n",
       "0           0  adelaide desalination        SA1   \n",
       "1           1                 aldoga       QLD1   \n",
       "2           2            amcor glass        SA1   \n",
       "3           3               angaston        SA1   \n",
       "6           6                 ararat       VIC1   \n",
       "7           7                avonlie       NSW1   \n",
       "8           8                  awaba       NSW1   \n",
       "10         10           baking board       QLD1   \n",
       "11         11             bald hills       VIC1   \n",
       "12         12               ballarat       VIC1   \n",
       "\n",
       "                      __best_name  __best_score matched_facility_id  \\\n",
       "0                       appin csm         100.0                 NaN   \n",
       "1              avonlie solar farm         100.0                 NaN   \n",
       "2          awaba renewable energy         100.0                 NaN   \n",
       "3                 bango wind farm         100.0                 NaN   \n",
       "6                beryl solar farm         100.0                 NaN   \n",
       "7   newtricity developments biala         100.0                 NaN   \n",
       "8               blayney wind farm         100.0                 NaN   \n",
       "10            boco rock wind farm         100.0                 NaN   \n",
       "11            bodangora wind farm         100.0                 NaN   \n",
       "12               bomen solar farm         100.0                 NaN   \n",
       "\n",
       "   match_strategy  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "6             NaN  \n",
       "7             NaN  \n",
       "8             NaN  \n",
       "10            NaN  \n",
       "11            NaN  \n",
       "12            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected (top 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>region_api</th>\n",
       "      <th>__best_name</th>\n",
       "      <th>__best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>anglesea</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>dubbo solar hub</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>appin</td>\n",
       "      <td>NSW1</td>\n",
       "      <td>broadwater power</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>bairnsdale</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>belrose lfg</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>bankstown sports club</td>\n",
       "      <td>NSW1</td>\n",
       "      <td>essential energy generation broken hill gas tu...</td>\n",
       "      <td>73.333336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>bannerton</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>bomen solar farm</td>\n",
       "      <td>46.666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>barker inlet</td>\n",
       "      <td>SA1</td>\n",
       "      <td>albury solar</td>\n",
       "      <td>42.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>bell bay</td>\n",
       "      <td>TAS1</td>\n",
       "      <td>oakey 1 solar farm</td>\n",
       "      <td>46.153847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>bell bay</td>\n",
       "      <td>TAS1</td>\n",
       "      <td>australand</td>\n",
       "      <td>44.444443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>41</td>\n",
       "      <td>bomen</td>\n",
       "      <td>NSW1</td>\n",
       "      <td>cullerin wind farm</td>\n",
       "      <td>46.153847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>45</td>\n",
       "      <td>braemar 2</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>broadwater power</td>\n",
       "      <td>53.846153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_api              name_norm region_api  \\\n",
       "4           4               anglesea       VIC1   \n",
       "5           5                  appin       NSW1   \n",
       "9           9             bairnsdale       VIC1   \n",
       "16         16  bankstown sports club       NSW1   \n",
       "17         17              bannerton       VIC1   \n",
       "18         20           barker inlet        SA1   \n",
       "21         24               bell bay       TAS1   \n",
       "22         25               bell bay       TAS1   \n",
       "36         41                  bomen       NSW1   \n",
       "40         45              braemar 2       QLD1   \n",
       "\n",
       "                                          __best_name  __best_score  \n",
       "4                                     dubbo solar hub     50.000000  \n",
       "5                                    broadwater power     56.000000  \n",
       "9                                         belrose lfg     50.000000  \n",
       "16  essential energy generation broken hill gas tu...     73.333336  \n",
       "17                                   bomen solar farm     46.666668  \n",
       "18                                       albury solar     42.105263  \n",
       "21                                 oakey 1 solar farm     46.153847  \n",
       "22                                         australand     44.444443  \n",
       "36                                 cullerin wind farm     46.153847  \n",
       "40                                   broadwater power     53.846153  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 2: Fuzzy match by name_norm within the same region\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"RapidFuzz is required. Install it via: pip install rapidfuzz\") from e\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure tracking columns exist on api2.\"\"\"\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    \"\"\"Print compact cumulative progress.\"\"\"\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    \"\"\"Display only columns that actually exist to avoid KeyError.\"\"\"\n",
    "    if title:\n",
    "        print(title)\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    if cols:\n",
    "        display(df[cols].head(n))\n",
    "    else:\n",
    "        display(df.head(n))\n",
    "\n",
    "# ---------- ensure trackers ----------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# ---------- guards ----------\n",
    "req_api_cols = [\"name_norm\", \"region_api\"]\n",
    "missing_api = [c for c in req_api_cols if c not in api2.columns]\n",
    "if missing_api:\n",
    "    raise ValueError(f\"api2 is missing required columns: {missing_api}\")\n",
    "\n",
    "req_db_cols = [\"name_norm\", \"region_db\"]\n",
    "missing_db = [c for c in req_db_cols if c not in db2.columns]\n",
    "if missing_db:\n",
    "    raise ValueError(f\"db2 is missing required columns: {missing_db}\")\n",
    "\n",
    "# Choose an identifier to store into matched_facility_id (priority order)\n",
    "db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 does not have any ID-like columns: facility_id / facility_code / facility_name\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "print(f\"[Attempt 2] Using '{CHOSEN_DB_ID_COL}' from db2 as the match identifier.\")\n",
    "\n",
    "# ---------- parameters ----------\n",
    "FUZZ_THRESHOLD = 90   # adjust later if needed\n",
    "SCORER = fuzz.token_set_ratio\n",
    "STRATEGY_LABEL = f\"fuzzy_name_region_tokenset_{FUZZ_THRESHOLD}\"\n",
    "\n",
    "# ---------- build candidates (only rows not yet matched) ----------\n",
    "cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "cand = cand[cand[\"name_norm\"].notna()]  # need a name to compare\n",
    "\n",
    "# ---------- prepare db reference ----------\n",
    "db_ref = db2.copy()\n",
    "db_ref = db_ref[db_ref[\"name_norm\"].notna() & db_ref[CHOSEN_DB_ID_COL].notna()].copy()\n",
    "db_ref[\"__chosen_id\"] = db_ref[CHOSEN_DB_ID_COL].astype(str)\n",
    "\n",
    "# Group available choices by region to keep comparisons relevant\n",
    "region_to_choices = (\n",
    "    db_ref.groupby(\"region_db\")\n",
    "          .apply(lambda g: list(zip(g[\"name_norm\"].astype(str).tolist(),\n",
    "                                    g[\"__chosen_id\"].tolist())))\n",
    "          .to_dict()\n",
    ")\n",
    "\n",
    "# Keep only rows whose region has choices\n",
    "cand[\"__has_choices\"] = cand[\"region_api\"].map(lambda r: r in region_to_choices)\n",
    "cand_work = cand[cand[\"__has_choices\"]].copy()\n",
    "\n",
    "# ---------- fuzzy matching per region ----------\n",
    "best_ids, best_scores, best_names = [], [], []\n",
    "\n",
    "for region, g in cand_work.groupby(\"region_api\"):\n",
    "    choices = region_to_choices.get(region, [])\n",
    "    if not choices:\n",
    "        n = len(g)\n",
    "        best_ids.extend([np.nan]*n)\n",
    "        best_scores.extend([np.nan]*n)\n",
    "        best_names.extend([np.nan]*n)\n",
    "        continue\n",
    "\n",
    "    choice_names = [nm for nm, _id in choices]\n",
    "    choice_ids   = [ _id for nm, _id in choices]\n",
    "\n",
    "    queries = g[\"name_norm\"].astype(str).tolist()\n",
    "    scores_mat = process.cdist(queries, choice_names, scorer=SCORER, workers=0)\n",
    "    argmax = scores_mat.argmax(axis=1)\n",
    "    scores = scores_mat.max(axis=1)\n",
    "\n",
    "    best_ids.extend([choice_ids[i] for i in argmax])\n",
    "    best_scores.extend(scores.tolist())\n",
    "    best_names.extend([choice_names[i] for i in argmax])\n",
    "\n",
    "cand_work[\"__best_id\"] = best_ids\n",
    "cand_work[\"__best_score\"] = best_scores\n",
    "cand_work[\"__best_name\"] = best_names\n",
    "\n",
    "accepted = cand_work[cand_work[\"__best_score\"] >= FUZZ_THRESHOLD].copy()\n",
    "rejected = cand_work[cand_work[\"__best_score\"] < FUZZ_THRESHOLD].copy()\n",
    "no_region_choices = cand[~cand[\"__has_choices\"]]\n",
    "\n",
    "# ---------- write back to api2 ----------\n",
    "if not accepted.empty:\n",
    "    api_idx = accepted[\"index_api\"].values\n",
    "    api2.loc[api_idx, \"matched_facility_id\"] = accepted[\"__best_id\"].astype(str).values\n",
    "    api2.loc[api_idx, \"match_strategy\"] = STRATEGY_LABEL\n",
    "\n",
    "# ---------- summaries ----------\n",
    "print(f\"Fuzzy accepted (>= {FUZZ_THRESHOLD}): {len(accepted)}\")\n",
    "print(f\"Fuzzy below threshold: {len(rejected)}\")\n",
    "print(f\"No region choices: {len(no_region_choices)}\")\n",
    "_progress(api2, label=\"Attempt 2: fuzzy name within region\")\n",
    "\n",
    "# ---------- safe previews ----------\n",
    "_safe_preview(\n",
    "    accepted,\n",
    "    desired_cols=[\n",
    "        \"index_api\",\"facility_name_api\",\"name_norm\",\"region_api\",\n",
    "        \"__best_name\",\"__best_score\",\"matched_facility_id\",\"match_strategy\"\n",
    "    ],\n",
    "    n=10,\n",
    "    title=\"Accepted (top 10)\"\n",
    ")\n",
    "_safe_preview(\n",
    "    rejected,\n",
    "    desired_cols=[\n",
    "        \"index_api\",\"facility_name_api\",\"name_norm\",\"region_api\",\n",
    "        \"__best_name\",\"__best_score\"\n",
    "    ],\n",
    "    n=10,\n",
    "    title=\"Rejected (top 10)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 3] Using 'facility_code' (api2) ↔ 'facility_code' (db2) for exact code match.\n",
      "[Attempt 3] Writing identifier from db2 column: 'facility_code'.\n",
      "[Attempt 3] Region consistency enabled: 'region_api' ↔ 'region_db'.\n",
      "Exact code matches in this attempt: 0\n",
      "Unmatched after exact code in this attempt: 236\n",
      "[Attempt 3: exact facility code] total rows: 514\n",
      "[Attempt 3: exact facility code] matched rows: 278\n",
      "[Attempt 3: exact facility code] remaining unmatched: 236\n",
      "[Attempt 3: exact facility code] progress: 54.09%\n",
      "Matched (sample)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_code</th>\n",
       "      <th>__chosen_id</th>\n",
       "      <th>match_strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_api, facility_code, __chosen_id, match_strategy]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched (sample)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_code</th>\n",
       "      <th>region_api</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>APS</td>\n",
       "      <td>VIC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>APPIN</td>\n",
       "      <td>NSW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>DEIBDL</td>\n",
       "      <td>VIC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>BANKSPT</td>\n",
       "      <td>NSW1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>BANNSP</td>\n",
       "      <td>VIC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>BARKIPS</td>\n",
       "      <td>SA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>BBDISEL1</td>\n",
       "      <td>TAS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>BELLBAY</td>\n",
       "      <td>TAS1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api facility_code region_api\n",
       "0          4           APS       VIC1\n",
       "1          5         APPIN       NSW1\n",
       "2          9        DEIBDL       VIC1\n",
       "3         16       BANKSPT       NSW1\n",
       "4         17        BANNSP       VIC1\n",
       "5         20       BARKIPS        SA1\n",
       "6         24      BBDISEL1       TAS1\n",
       "7         25       BELLBAY       TAS1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 3: Exact match by facility code\n",
    "# Robust to duplicate column names in db2; includes region check, ID fallback, and progress\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df: pd.DataFrame, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _get_single_series(df: pd.DataFrame, colname: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Return a single 1D Series for the given colname even if df has duplicated column names.\n",
    "    If multiple columns share the same name, take the first one.\n",
    "    \"\"\"\n",
    "    # Boolean mask of columns with this name\n",
    "    mask = df.columns == colname\n",
    "    count = mask.sum()\n",
    "    if count == 0:\n",
    "        raise KeyError(f\"Column '{colname}' not found.\")\n",
    "    if count == 1:\n",
    "        return df.loc[:, colname]\n",
    "    # If duplicated names, take the first occurrence\n",
    "    first_idx = np.flatnonzero(mask)[0]\n",
    "    return df.iloc[:, first_idx]\n",
    "\n",
    "# ---------- ensure trackers ----------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# ---------- detect code columns ----------\n",
    "api_code_col = _pick_first_existing(api2, [\"facility_code_api\", \"facility_code\", \"code\"])\n",
    "db_code_col  = _pick_first_existing(db2,  [\"facility_code\", \"code\"])\n",
    "\n",
    "if api_code_col is None:\n",
    "    raise ValueError(\"No facility code column found on api2 (looked for: facility_code_api / facility_code / code).\")\n",
    "if db_code_col is None:\n",
    "    raise ValueError(\"No facility code column found on db2 (looked for: facility_code / code).\")\n",
    "\n",
    "# Optional region consistency\n",
    "api_region_col = \"region_api\" if \"region_api\" in api2.columns else None\n",
    "db_region_col  = \"region_db\"  if \"region_db\"  in db2.columns else None\n",
    "use_region_check = api_region_col is not None and db_region_col is not None\n",
    "\n",
    "# Choose an identifier to write into matched_facility_id\n",
    "db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 has no identifier columns (expected one of: facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "print(f\"[Attempt 3] Using '{api_code_col}' (api2) ↔ '{db_code_col}' (db2) for exact code match.\")\n",
    "print(f\"[Attempt 3] Writing identifier from db2 column: '{CHOSEN_DB_ID_COL}'.\")\n",
    "if use_region_check:\n",
    "    print(f\"[Attempt 3] Region consistency enabled: '{api_region_col}' ↔ '{db_region_col}'.\")\n",
    "\n",
    "# ---------- candidates: only rows not yet matched and having a code ----------\n",
    "cand = api2[api2[\"matched_facility_id\"].isna() & api2[api_code_col].notna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "cand[api_code_col] = cand[api_code_col].astype(str)\n",
    "\n",
    "# ---------- prepare db reference robustly ----------\n",
    "db_ref = db2.copy()\n",
    "\n",
    "# Build single-series keys even if names are duplicated\n",
    "db_ref[\"__code_key\"] = _get_single_series(db_ref, db_code_col).astype(str)\n",
    "\n",
    "if use_region_check:\n",
    "    db_ref[\"__region_key\"] = _get_single_series(db_ref, db_region_col).astype(str)\n",
    "\n",
    "# Also ensure single-series for chosen ID\n",
    "id_series = _get_single_series(db_ref, CHOSEN_DB_ID_COL)\n",
    "db_ref[\"__chosen_id\"] = id_series.astype(str)\n",
    "\n",
    "# Keep only needed columns and drop rows missing keys/ids\n",
    "keep_cols = [\"__code_key\", \"__chosen_id\"] + ([\"__region_key\"] if use_region_check else [])\n",
    "db_ref = db_ref[keep_cols].dropna(subset=[\"__code_key\", \"__chosen_id\"])\n",
    "\n",
    "# Deduplicate by first occurrence per code (+ region if applicable)\n",
    "group_keys = [\"__code_key\"] + ([\"__region_key\"] if use_region_check else [])\n",
    "db_ref = db_ref.groupby(group_keys, as_index=False).first()\n",
    "\n",
    "# ---------- merge by code (+ region if available) ----------\n",
    "left_keys = [api_code_col] + ([api_region_col] if use_region_check else [])\n",
    "right_keys = [\"__code_key\"] + ([\"__region_key\"] if use_region_check else [])\n",
    "\n",
    "merged = cand.merge(\n",
    "    db_ref,\n",
    "    left_on=left_keys,\n",
    "    right_on=right_keys,\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_api\", \"_db\")\n",
    ")\n",
    "\n",
    "# Determine matches by presence of identifier\n",
    "is_matched = merged[\"__chosen_id\"].notna()\n",
    "matched = merged[is_matched].copy()\n",
    "unmatched = merged[~is_matched].copy()\n",
    "\n",
    "# ---------- write back ----------\n",
    "if not matched.empty:\n",
    "    api_idx = matched[\"index_api\"].values\n",
    "    api2.loc[api_idx, \"matched_facility_id\"] = matched[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[api_idx, \"match_strategy\"] = \"exact_facility_code\"\n",
    "\n",
    "# ---------- summaries ----------\n",
    "print(f\"Exact code matches in this attempt: {len(matched)}\")\n",
    "print(f\"Unmatched after exact code in this attempt: {len(unmatched)}\")\n",
    "_progress(api2, label=\"Attempt 3: exact facility code\")\n",
    "\n",
    "# ---------- safe previews ----------\n",
    "def _safe_preview(df, desired_cols, n=8, title=None):\n",
    "    if title: print(title)\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "_safe_preview(matched, [\"index_api\", api_code_col, \"__chosen_id\", \"match_strategy\"], n=8, title=\"Matched (sample)\")\n",
    "_safe_preview(unmatched, [\"index_api\", api_code_col] + ([api_region_col] if use_region_check else []), n=8, title=\"Unmatched (sample)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 4: Geospatial nearest-by-coordinates within region\n",
    "# Fix: write-back uses positional indices (iloc) after mapping labels -> positions\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# MAX_KM = 15.0\n",
    "# EARTH_R_KM = 6371.0\n",
    "# STRATEGY_LABEL = f\"geo_nearest_within_region_le_{int(MAX_KM)}km\"\n",
    "\n",
    "# def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     if \"matched_facility_id\" not in df.columns:\n",
    "#         df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "#     if \"match_strategy\" not in df.columns:\n",
    "#         df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "#     return df\n",
    "\n",
    "# def _progress(a2: pd.DataFrame, label: str):\n",
    "#     total = len(a2)\n",
    "#     matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "#     remaining = total - matched\n",
    "#     pct = (matched / total * 100.0) if total else 0.0\n",
    "#     print(f\"[{label}] total rows: {total}\")\n",
    "#     print(f\"[{label}] matched rows: {matched}\")\n",
    "#     print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "#     print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "# def _pick_first_existing(df: pd.DataFrame, options):\n",
    "#     for c in options:\n",
    "#         if c in df.columns:\n",
    "#             return c\n",
    "#     return None\n",
    "\n",
    "# def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "#     lat1 = np.radians(lat1.astype(float)); lon1 = np.radians(lon1.astype(float))\n",
    "#     lat2 = np.radians(lat2.astype(float)); lon2 = np.radians(lon2.astype(float))\n",
    "#     dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "#     a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*(np.sin(dlon/2.0)**2)\n",
    "#     return EARTH_R_KM * 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "\n",
    "# def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "#     if title: print(title)\n",
    "#     cols = [c for c in desired_cols if c in df.columns]\n",
    "#     display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# # identifier to write back\n",
    "# db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "# if not db_id_candidates:\n",
    "#     raise ValueError(\"db2 has no identifier columns (facility_id / facility_code / facility_name).\")\n",
    "# CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "# api_region_col = _pick_first_existing(api2, [\"region_api\",\"region\"])\n",
    "# db_region_col  = _pick_first_existing(db2,  [\"region_db\",\"region\"])\n",
    "# api_lat_col    = _pick_first_existing(api2, [\"lat_api\",\"latitude\",\"lat\"])\n",
    "# api_lon_col    = _pick_first_existing(api2, [\"lng_api\",\"longitude\",\"lon\",\"long\"])\n",
    "# db_lat_col     = _pick_first_existing(db2,  [\"latitude\",\"lat\"])\n",
    "# db_lon_col     = _pick_first_existing(db2,  [\"longitude\",\"lon\",\"long\"])\n",
    "\n",
    "# missing = []\n",
    "# for nm, col in [(\"api_region\",api_region_col),(\"db_region\",db_region_col),\n",
    "#                 (\"api_lat\",api_lat_col),(\"api_lon\",api_lon_col),\n",
    "#                 (\"db_lat\",db_lat_col),(\"db_lon\",db_lon_col)]:\n",
    "#     if col is None: missing.append(nm)\n",
    "# if missing:\n",
    "#     raise ValueError(f\"Attempt 4 needs these columns: {missing}\")\n",
    "\n",
    "# print(f\"[Attempt 4r] Coords api2({api_lat_col},{api_lon_col}) ↔ db2({db_lat_col},{db_lon_col}); region: {api_region_col} ↔ {db_region_col}\")\n",
    "# print(f\"[Attempt 4r] Writing identifier: '{CHOSEN_DB_ID_COL}', radius ≤ {MAX_KM} km\")\n",
    "\n",
    "# # only unmatched with coords\n",
    "# cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "# cand = cand[cand[api_lat_col].notna() & cand[api_lon_col].notna()].copy()\n",
    "# cand = cand.reset_index().rename(columns={\"index\":\"index_api\"})  # label index of api2\n",
    "\n",
    "# db_ref = db2.copy()\n",
    "# db_ref = db_ref[db_ref[db_lat_col].notna() & db_ref[db_lon_col].notna() & db_ref[CHOSEN_DB_ID_COL].notna()].copy()\n",
    "\n",
    "# accepted_rows_lbl, accepted_ids, accepted_dists = [], [], []\n",
    "# rejected_rows_lbl, rejected_best = [], []\n",
    "# no_choices_rows_lbl = []\n",
    "\n",
    "# for rg, g_api in cand.groupby(cand[api_region_col].astype(str)):\n",
    "#     g_db = db_ref[db_ref[db_region_col].astype(str)==rg].copy()\n",
    "#     if g_db.empty:\n",
    "#         no_choices_rows_lbl.extend(g_api[\"index_api\"].tolist())\n",
    "#         continue\n",
    "\n",
    "#     lat_api = g_api[api_lat_col].astype(float).to_numpy()\n",
    "#     lon_api = g_api[api_lon_col].astype(float).to_numpy()\n",
    "#     lat_db  = g_db[db_lat_col].astype(float).to_numpy()\n",
    "#     lon_db  = g_db[db_lon_col].astype(float).to_numpy()\n",
    "\n",
    "#     best_j = []\n",
    "#     best_dist = []\n",
    "#     for i in range(len(g_api)):\n",
    "#         d = _haversine_km(np.full(len(g_db), lat_api[i]), np.full(len(g_db), lon_api[i]), lat_db, lon_db)\n",
    "#         j = int(np.argmin(d)); best_j.append(j); best_dist.append(float(d[j]))\n",
    "\n",
    "#     ids_db = g_db[CHOSEN_DB_ID_COL].astype(str).to_numpy()\n",
    "#     best_ids_here = [ids_db[j] for j in best_j]\n",
    "\n",
    "#     idx_lbl = g_api[\"index_api\"].to_numpy()\n",
    "#     accept_mask = np.array(best_dist) <= MAX_KM\n",
    "\n",
    "#     accepted_rows_lbl.extend(idx_lbl[accept_mask].tolist())\n",
    "#     accepted_ids.extend(np.array(best_ids_here)[accept_mask].tolist())\n",
    "#     accepted_dists.extend(np.array(best_dist)[accept_mask].tolist())\n",
    "\n",
    "#     rejected_rows_lbl.extend(idx_lbl[~accept_mask].tolist())\n",
    "#     rejected_best.extend(np.array(best_dist)[~accept_mask].tolist())\n",
    "\n",
    "# # Map label indices -> positional indices and write via .iloc\n",
    "# if accepted_rows_lbl:\n",
    "#     pos_idx = api2.index.get_indexer(accepted_rows_lbl)\n",
    "#     valid_mask = pos_idx != -1\n",
    "#     if valid_mask.any():\n",
    "#         pos_idx_valid = pos_idx[valid_mask]\n",
    "#         ids_valid = np.array(accepted_ids)[valid_mask]\n",
    "#         dists_valid = np.array(accepted_dists)[valid_mask]\n",
    "#         api2.iloc[pos_idx_valid, api2.columns.get_loc(\"matched_facility_id\")] = ids_valid.astype(str)\n",
    "#         api2.iloc[pos_idx_valid, api2.columns.get_loc(\"match_strategy\")] = STRATEGY_LABEL\n",
    "#         # distance column\n",
    "#         if \"matched_distance_km\" not in api2.columns:\n",
    "#             api2[\"matched_distance_km\"] = np.nan\n",
    "#         api2.iloc[pos_idx_valid, api2.columns.get_loc(\"matched_distance_km\")] = dists_valid.astype(float)\n",
    "#         print(f\"[Attempt 4r] Wrote back {valid_mask.sum()} of {len(accepted_rows_lbl)} accepted (index labels mapped).\")\n",
    "#     else:\n",
    "#         print(\"[Attempt 4r] Warning: none of the accepted index labels mapped to api2 positions.\")\n",
    "# else:\n",
    "#     print(\"[Attempt 4r] No accepted rows to write back.\")\n",
    "\n",
    "# print(f\"Geo accepted (≤ {MAX_KM} km): {len(accepted_rows_lbl)}\")\n",
    "# print(f\"Geo rejected (best > {MAX_KM} km): {len(rejected_rows_lbl)}\")\n",
    "# print(f\"No db choices in region: {len(no_choices_rows_lbl)}\")\n",
    "# _progress(api2, label=\"Attempt 4r: geo nearest within region\")\n",
    "\n",
    "# # previews\n",
    "# acc_df = api2.loc[accepted_rows_lbl, [api_region_col, api_lat_col, api_lon_col, \"matched_facility_id\", \"match_strategy\", \"matched_distance_km\"]].copy() if accepted_rows_lbl else pd.DataFrame()\n",
    "# rej_df = api2.loc[rejected_rows_lbl, [api_region_col, api_lat_col, api_lon_col]].copy() if rejected_rows_lbl else pd.DataFrame()\n",
    "# _safe_preview(acc_df, [api_region_col, \"matched_facility_id\", \"match_strategy\", \"matched_distance_km\"], 10, \"Accepted by geo (top 10)\")\n",
    "# _safe_preview(rej_df, [api_region_col, api_lat_col, api_lon_col], 10, \"Rejected by geo (top 10)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 5] Using 'facility_code' as identifier; threshold ≥ 94; no state gate.\n",
      "Fuzzy accepted (>= 94): 120\n",
      "Fuzzy below threshold: 105\n",
      "[Attempt 5: fuzzy name without region] total rows: 514\n",
      "[Attempt 5: fuzzy name without region] matched rows: 398\n",
      "[Attempt 5: fuzzy name without region] remaining unmatched: 116\n",
      "[Attempt 5: fuzzy name without region] progress: 77.43%\n",
      "Accepted (top 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>__best_name</th>\n",
       "      <th>__score</th>\n",
       "      <th>__chosen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>gunning</td>\n",
       "      <td>gunning wind farm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>copeton</td>\n",
       "      <td>copeton hydro</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>appin</td>\n",
       "      <td>appin csm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>brooklyn</td>\n",
       "      <td>brooklyn lfg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>browns plains</td>\n",
       "      <td>browns plains lfg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>eildon</td>\n",
       "      <td>eildon hydro</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148</td>\n",
       "      <td>german creek</td>\n",
       "      <td>german creek cmm</td>\n",
       "      <td>100.0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>205</td>\n",
       "      <td>jacks gully</td>\n",
       "      <td>jacks gully lfg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>glenbawn</td>\n",
       "      <td>glenbawn hydro</td>\n",
       "      <td>100.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>320</td>\n",
       "      <td>oaky creek 2</td>\n",
       "      <td>oaky creek</td>\n",
       "      <td>100.0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api      name_norm        __best_name  __score __chosen_id\n",
       "0        172        gunning  gunning wind farm    100.0           1\n",
       "1        103        copeton      copeton hydro    100.0          10\n",
       "2          5          appin          appin csm    100.0         101\n",
       "3         53       brooklyn       brooklyn lfg    100.0         108\n",
       "4         55  browns plains  browns plains lfg    100.0         110\n",
       "5        130         eildon       eildon hydro    100.0          12\n",
       "6        148   german creek   german creek cmm    100.0         121\n",
       "7        205    jacks gully    jacks gully lfg    100.0         125\n",
       "8        151       glenbawn     glenbawn hydro    100.0          13\n",
       "9        320   oaky creek 2         oaky creek    100.0         138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected (top 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>__score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>53.333332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>53.658535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>54.545456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>51.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>52.631580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65</td>\n",
       "      <td>58.823528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67</td>\n",
       "      <td>88.888885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83</td>\n",
       "      <td>46.666668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api    __score\n",
       "0          4  53.333332\n",
       "1          9  60.000000\n",
       "2         16  53.658535\n",
       "3         20  54.545456\n",
       "4         45  51.851852\n",
       "5         58  52.631580\n",
       "6         65  58.823528\n",
       "7         67  88.888885\n",
       "8         74  75.000000\n",
       "9         83  46.666668"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 5: Fuzzy match by name_norm without region constraint\n",
    "# - Optional state_code constraint if both sides have it\n",
    "# - High threshold to avoid false positives\n",
    "# - One-to-one resolution: keep highest-score per chosen_id\n",
    "# - Progress reporting and safe previews\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"RapidFuzz is required. Install it via: pip install rapidfuzz\") from e\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "def _pick_first_existing(df: pd.DataFrame, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# ---------- ensure trackers ----------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# ---------- guards & column picks ----------\n",
    "# mandatory names\n",
    "if \"name_norm\" not in api2.columns or \"name_norm\" not in db2.columns:\n",
    "    raise ValueError(\"Both api2 and db2 must have a 'name_norm' column for Attempt 5.\")\n",
    "\n",
    "# optional state constraint\n",
    "api_state_col = _pick_first_existing(api2, [\"state_code\", \"state\"])\n",
    "db_state_col  = _pick_first_existing(db2,  [\"state_code\", \"state\"])\n",
    "use_state_gate = api_state_col is not None and db_state_col is not None\n",
    "\n",
    "# identifier to store into matched_facility_id\n",
    "db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 does not have an identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "# ---------- parameters ----------\n",
    "FUZZ_THRESHOLD = 94  # higher because no region constraint\n",
    "SCORER = fuzz.token_set_ratio\n",
    "STRATEGY_LABEL = f\"fuzzy_name_no_region_tokenset_{FUZZ_THRESHOLD}\"\n",
    "\n",
    "print(f\"[Attempt 5] Using '{CHOSEN_DB_ID_COL}' as identifier; threshold ≥ {FUZZ_THRESHOLD}; \"\n",
    "      f\"{'with state gate' if use_state_gate else 'no state gate'}.\")\n",
    "\n",
    "# ---------- build candidates (unmatched only) ----------\n",
    "cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "cand = cand[cand[\"name_norm\"].notna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "\n",
    "# ---------- prepare db reference ----------\n",
    "db_ref = db2.copy()\n",
    "db_ref = db_ref[db_ref[\"name_norm\"].notna() & db_ref[CHOSEN_DB_ID_COL].notna()].copy()\n",
    "db_ref[\"__chosen_id\"] = db_ref[CHOSEN_DB_ID_COL].astype(str)\n",
    "if use_state_gate:\n",
    "    db_ref[\"__state\"] = db_ref[db_state_col].astype(str)\n",
    "\n",
    "# ---------- fuzzy match ----------\n",
    "accepted_rows = []\n",
    "accepted_ids = []\n",
    "accepted_scores = []\n",
    "accepted_best_names = []\n",
    "\n",
    "rejected_rows = []\n",
    "rejected_scores = []\n",
    "\n",
    "if use_state_gate:\n",
    "    # match within same state only\n",
    "    for st, g in cand.groupby(cand[api_state_col].astype(str)):\n",
    "        ref = db_ref[db_ref[\"__state\"] == str(st)]\n",
    "        if ref.empty:\n",
    "            # no choices for this state; skip\n",
    "            continue\n",
    "\n",
    "        choice_names = ref[\"name_norm\"].astype(str).tolist()\n",
    "        choice_ids   = ref[\"__chosen_id\"].tolist()\n",
    "\n",
    "        queries = g[\"name_norm\"].astype(str).tolist()\n",
    "        scores_mat = process.cdist(queries, choice_names, scorer=SCORER, workers=0)\n",
    "        argmax = scores_mat.argmax(axis=1)\n",
    "        scores = scores_mat.max(axis=1)\n",
    "\n",
    "        sel = scores >= FUZZ_THRESHOLD\n",
    "        accepted_rows.extend(g[\"index_api\"].to_numpy()[sel].tolist())\n",
    "        accepted_ids.extend(np.array(choice_ids)[argmax][sel].tolist())\n",
    "        accepted_scores.extend(scores[sel].astype(float).tolist())\n",
    "        accepted_best_names.extend(np.array(choice_names)[argmax][sel].tolist())\n",
    "\n",
    "        rejected_rows.extend(g[\"index_api\"].to_numpy()[~sel].tolist())\n",
    "        rejected_scores.extend(scores[~sel].astype(float).tolist())\n",
    "else:\n",
    "    # global choices across all states\n",
    "    choice_names = db_ref[\"name_norm\"].astype(str).tolist()\n",
    "    choice_ids   = db_ref[\"__chosen_id\"].tolist()\n",
    "\n",
    "    queries = cand[\"name_norm\"].astype(str).tolist()\n",
    "    scores_mat = process.cdist(queries, choice_names, scorer=SCORER, workers=0)\n",
    "    argmax = scores_mat.argmax(axis=1)\n",
    "    scores = scores_mat.max(axis=1)\n",
    "\n",
    "    sel = scores >= FUZZ_THRESHOLD\n",
    "    accepted_rows.extend(cand[\"index_api\"].to_numpy()[sel].tolist())\n",
    "    accepted_ids.extend(np.array(choice_ids)[argmax][sel].tolist())\n",
    "    accepted_scores.extend(scores[sel].astype(float).tolist())\n",
    "    accepted_best_names.extend(np.array(choice_names)[argmax][sel].tolist())\n",
    "\n",
    "    rejected_rows.extend(cand[\"index_api\"].to_numpy()[~sel].tolist())\n",
    "    rejected_scores.extend(scores[~sel].astype(float).tolist())\n",
    "\n",
    "# ---------- one-to-one resolution: keep highest score per chosen_id ----------\n",
    "if accepted_rows:\n",
    "    acc_df = pd.DataFrame({\n",
    "        \"index_api\": accepted_rows,\n",
    "        \"__chosen_id\": accepted_ids,\n",
    "        \"__score\": accepted_scores,\n",
    "        \"__best_name\": accepted_best_names\n",
    "    })\n",
    "    # keep only the highest score per chosen_id\n",
    "    acc_df = acc_df.sort_values([\"__chosen_id\", \"__score\"], ascending=[True, False])\n",
    "    acc_df = acc_df.groupby(\"__chosen_id\", as_index=False).first()\n",
    "\n",
    "    # write back into api2\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_facility_id\"] = acc_df[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"match_strategy\"] = STRATEGY_LABEL\n",
    "\n",
    "# ---------- summaries ----------\n",
    "print(f\"Fuzzy accepted (>= {FUZZ_THRESHOLD}): {len(set(accepted_ids)) if accepted_rows else 0}\")\n",
    "print(f\"Fuzzy below threshold: {len(rejected_rows)}\")\n",
    "_progress(api2, label=\"Attempt 5: fuzzy name without region\")\n",
    "\n",
    "# ---------- safe previews ----------\n",
    "if accepted_rows:\n",
    "    preview_acc = acc_df.merge(\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[[\"index_api\",\"facility_name_api\",\"name_norm\"]]\n",
    "        if \"facility_name_api\" in api2.columns else\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[[\"index_api\",\"name_norm\"]],\n",
    "        on=\"index_api\", how=\"left\"\n",
    "    )\n",
    "    _safe_preview(preview_acc,\n",
    "                  [\"index_api\",\"facility_name_api\",\"name_norm\",\"__best_name\",\"__score\",\"__chosen_id\"],\n",
    "                  n=10, title=\"Accepted (top 10)\")\n",
    "else:\n",
    "    print(\"No accepted rows to preview.\")\n",
    "\n",
    "rej_df = pd.DataFrame({\"index_api\": rejected_rows, \"__score\": rejected_scores})\n",
    "_safe_preview(rej_df, [\"index_api\",\"__score\"], n=10, title=\"Rejected (top 10)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 6] Fuzzy threshold >= 85 and geo gate <= 25.0 km\n",
      "[Attempt 6] Using id 'facility_code'. State gate: OFF\n",
      "Hybrid accepted (score >= 85 and dist <= 25.0 km): 0\n",
      "[Attempt 6: hybrid fuzzy+geo] total rows: 514\n",
      "[Attempt 6: hybrid fuzzy+geo] matched rows: 398\n",
      "[Attempt 6: hybrid fuzzy+geo] remaining unmatched: 116\n",
      "[Attempt 6: hybrid fuzzy+geo] progress: 77.43%\n",
      "No accepted rows to preview.\n"
     ]
    }
   ],
   "source": [
    "# Attempt 6: Hybrid fuzzy + geographic gate (state-aware)\n",
    "# - Only process rows still unmatched\n",
    "# - Search candidates within the same state (if available)\n",
    "# - Accept if fuzzy score >= FUZZ_THRESHOLD AND distance <= MAX_KM\n",
    "# - Robust write-back and progress reporting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"RapidFuzz is required. Install it via: pip install rapidfuzz\") from e\n",
    "\n",
    "# ---------- parameters ----------\n",
    "FUZZ_THRESHOLD = 85   # lower than Attempt 5 because we add a geo gate\n",
    "MAX_KM = 25.0         # geographic acceptance radius\n",
    "EARTH_R_KM = 6371.0\n",
    "STRATEGY_LABEL = f\"hybrid_fuzzy{FUZZ_THRESHOLD}_geo_le{int(MAX_KM)}km_state\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df: pd.DataFrame, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(lat1.astype(float)); lon1 = np.radians(lon1.astype(float))\n",
    "    lat2 = np.radians(lat2.astype(float)); lon2 = np.radians(lon2.astype(float))\n",
    "    dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*(np.sin(dlon/2.0)**2)\n",
    "    return EARTH_R_KM * 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# ---------- prepare ----------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# required cols\n",
    "for nm in [\"name_norm\"]:\n",
    "    if nm not in api2.columns or nm not in db2.columns:\n",
    "        raise ValueError(f\"Attempt 6 requires column '{nm}' on both api2 and db2.\")\n",
    "\n",
    "# identifier to write back\n",
    "db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 has no identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "# detect state and coords\n",
    "api_state_col = _pick_first_existing(api2, [\"state_code\",\"state\"])\n",
    "db_state_col  = _pick_first_existing(db2,  [\"state_code\",\"state\"])\n",
    "use_state = api_state_col is not None and db_state_col is not None\n",
    "\n",
    "api_lat_col = _pick_first_existing(api2, [\"lat_api\",\"latitude\",\"lat\"])\n",
    "api_lon_col = _pick_first_existing(api2, [\"lng_api\",\"longitude\",\"lon\",\"long\"])\n",
    "db_lat_col  = _pick_first_existing(db2,  [\"latitude\",\"lat\"])\n",
    "db_lon_col  = _pick_first_existing(db2,  [\"longitude\",\"lon\",\"long\"])\n",
    "\n",
    "for name, col in [(\"api_lat\",api_lat_col),(\"api_lon\",api_lon_col),(\"db_lat\",db_lat_col),(\"db_lon\",db_lon_col)]:\n",
    "    if col is None:\n",
    "        raise ValueError(f\"Attempt 6 requires coordinate column: {name}\")\n",
    "\n",
    "print(f\"[Attempt 6] Fuzzy threshold >= {FUZZ_THRESHOLD} and geo gate <= {MAX_KM} km\")\n",
    "print(f\"[Attempt 6] Using id '{CHOSEN_DB_ID_COL}'. State gate: {'ON' if use_state else 'OFF'}\")\n",
    "\n",
    "# ---------- candidates (still unmatched + with coords + name) ----------\n",
    "cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "cand = cand[cand[\"name_norm\"].notna() & cand[api_lat_col].notna() & cand[api_lon_col].notna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\":\"index_api\"})\n",
    "\n",
    "db_ref = db2.copy()\n",
    "db_ref = db_ref[db_ref[\"name_norm\"].notna() & db_ref[CHOSEN_DB_ID_COL].notna() &\n",
    "                db_ref[db_lat_col].notna() & db_ref[db_lon_col].notna()].copy()\n",
    "if use_state:\n",
    "    db_ref[\"__state\"] = db_ref[db_state_col].astype(str)\n",
    "\n",
    "accepted_rows_lbl, accepted_ids, accepted_scores, accepted_dists, accepted_best = [], [], [], [], []\n",
    "rejected_rows_lbl = []\n",
    "\n",
    "if use_state:\n",
    "    groups = cand.groupby(cand[api_state_col].astype(str))\n",
    "else:\n",
    "    # single group \"ALL\"\n",
    "    groups = [(\"ALL\", cand)]\n",
    "\n",
    "for grp_key, g in groups:\n",
    "    if isinstance(groups, list):\n",
    "        g = g  # already DataFrame\n",
    "    ref = db_ref if not use_state else db_ref[db_ref[\"__state\"] == str(grp_key)]\n",
    "    if ref.empty:\n",
    "        continue\n",
    "\n",
    "    choice_names = ref[\"name_norm\"].astype(str).tolist()\n",
    "    choice_ids   = ref[CHOSEN_DB_ID_COL].astype(str).tolist()\n",
    "    lat_db       = ref[db_lat_col].astype(float).to_numpy()\n",
    "    lon_db       = ref[db_lon_col].astype(float).to_numpy()\n",
    "\n",
    "    queries = g[\"name_norm\"].astype(str).tolist()\n",
    "    scores_mat = process.cdist(queries, choice_names, scorer=fuzz.token_set_ratio, workers=0)\n",
    "    argmax = scores_mat.argmax(axis=1)\n",
    "    scores = scores_mat.max(axis=1)\n",
    "\n",
    "    # nearest distance to the same best match candidate\n",
    "    lat_api = g[api_lat_col].astype(float).to_numpy()\n",
    "    lon_api = g[api_lon_col].astype(float).to_numpy()\n",
    "    best_lat = lat_db[argmax]\n",
    "    best_lon = lon_db[argmax]\n",
    "    dists = _haversine_km(lat_api, lon_api, best_lat, best_lon)\n",
    "\n",
    "    sel = (scores >= FUZZ_THRESHOLD) & (dists <= MAX_KM)\n",
    "    if sel.any():\n",
    "        accepted_rows_lbl.extend(g[\"index_api\"].to_numpy()[sel].tolist())\n",
    "        accepted_ids.extend(np.array(choice_ids)[argmax][sel].tolist())\n",
    "        accepted_scores.extend(scores[sel].astype(float).tolist())\n",
    "        accepted_dists.extend(dists[sel].astype(float).tolist())\n",
    "        accepted_best.extend(np.array(choice_names)[argmax][sel].tolist())\n",
    "\n",
    "    if (~sel).any():\n",
    "        rejected_rows_lbl.extend(g[\"index_api\"].to_numpy()[~sel].tolist())\n",
    "\n",
    "# ---------- one-to-one on accepted (keep highest score; if tie, keep closest) ----------\n",
    "gain = 0\n",
    "if accepted_rows_lbl:\n",
    "    acc_df = pd.DataFrame({\n",
    "        \"index_api\": accepted_rows_lbl,\n",
    "        \"__chosen_id\": accepted_ids,\n",
    "        \"__score\": accepted_scores,\n",
    "        \"__dist_km\": accepted_dists,\n",
    "        \"__best_name\": accepted_best\n",
    "    })\n",
    "    acc_df = acc_df.sort_values([\"__chosen_id\",\"__score\",\"__dist_km\"], ascending=[True, False, True])\n",
    "    acc_df = acc_df.groupby(\"__chosen_id\", as_index=False).first()\n",
    "    gain = len(acc_df)\n",
    "\n",
    "    # write back (label indices are original api2 index values)\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_facility_id\"] = acc_df[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"match_strategy\"] = STRATEGY_LABEL\n",
    "    if \"matched_distance_km\" not in api2.columns:\n",
    "        api2[\"matched_distance_km\"] = np.nan\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_distance_km\"] = acc_df[\"__dist_km\"].astype(float).values\n",
    "\n",
    "# ---------- summaries ----------\n",
    "print(f\"Hybrid accepted (score >= {FUZZ_THRESHOLD} and dist <= {MAX_KM} km): {gain}\")\n",
    "_progress(api2, label=\"Attempt 6: hybrid fuzzy+geo\")\n",
    "\n",
    "# ---------- previews ----------\n",
    "if gain > 0:\n",
    "    preview = acc_df.merge(\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[[\"index_api\",\"facility_name_api\",\"name_norm\"]]\n",
    "        if \"facility_name_api\" in api2.columns else\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[[\"index_api\",\"name_norm\"]],\n",
    "        on=\"index_api\", how=\"left\"\n",
    "    )\n",
    "    _safe_preview(preview,\n",
    "                  [\"index_api\",\"facility_name_api\",\"name_norm\",\"__best_name\",\"__score\",\"__dist_km\",\"__chosen_id\"],\n",
    "                  n=10, title=\"Accepted (top 10)\")\n",
    "else:\n",
    "    print(\"No accepted rows to preview.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 7] Identifier: 'facility_code'. Threshold ≥ 88. Prefer region: True, state: False\n",
      "Alias-fuzzy accepted (>= 88): 19\n",
      "[Attempt 7: alias fuzzy] total rows: 514\n",
      "[Attempt 7: alias fuzzy] matched rows: 417\n",
      "[Attempt 7: alias fuzzy] remaining unmatched: 97\n",
      "[Attempt 7: alias fuzzy] progress: 81.13%\n",
      "Accepted (top 10) — Attempt 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>alias_norm</th>\n",
       "      <th>__best_name</th>\n",
       "      <th>__score</th>\n",
       "      <th>__chosen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>eildon</td>\n",
       "      <td>eildon</td>\n",
       "      <td>eildon</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>lake bonney 3</td>\n",
       "      <td>lake bonney</td>\n",
       "      <td>lake bonney stage</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>woodlawn</td>\n",
       "      <td>woodlawn</td>\n",
       "      <td>woodlawn</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254</td>\n",
       "      <td>loy yang a</td>\n",
       "      <td>loy yang a</td>\n",
       "      <td>loy yang and mine</td>\n",
       "      <td>88.888885</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>bell bay</td>\n",
       "      <td>bell bay</td>\n",
       "      <td>bell bay thermal</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>224</td>\n",
       "      <td>kidston</td>\n",
       "      <td>kidston</td>\n",
       "      <td>kidston one qld</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>hornsdale 2</td>\n",
       "      <td>hornsdale</td>\n",
       "      <td>hornsdale reserve</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>146</td>\n",
       "      <td>gannawarra</td>\n",
       "      <td>gannawarra</td>\n",
       "      <td>gannawarra</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>316</td>\n",
       "      <td>oakey 2</td>\n",
       "      <td>oakey</td>\n",
       "      <td>oakey</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "      <td>glenrowan west</td>\n",
       "      <td>glenrowan west</td>\n",
       "      <td>glenrowan west</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api       name_norm      alias_norm        __best_name     __score  \\\n",
       "0        131          eildon          eildon             eildon  100.000000   \n",
       "1        235   lake bonney 3     lake bonney  lake bonney stage  100.000000   \n",
       "2        495        woodlawn        woodlawn           woodlawn  100.000000   \n",
       "3        254      loy yang a      loy yang a  loy yang and mine   88.888885   \n",
       "4         25        bell bay        bell bay   bell bay thermal  100.000000   \n",
       "5        224         kidston         kidston    kidston one qld  100.000000   \n",
       "6        193     hornsdale 2       hornsdale  hornsdale reserve  100.000000   \n",
       "7        146      gannawarra      gannawarra         gannawarra  100.000000   \n",
       "8        316         oakey 2           oakey              oakey  100.000000   \n",
       "9        156  glenrowan west  glenrowan west     glenrowan west  100.000000   \n",
       "\n",
       "  __chosen_id  \n",
       "0          12  \n",
       "1         218  \n",
       "2         219  \n",
       "3          23  \n",
       "4         369  \n",
       "5         493  \n",
       "6         506  \n",
       "7         609  \n",
       "8         616  \n",
       "9         645  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 7: Alias-based normalisation + fuzzy match (prefer same region/state)\n",
    "# - Build alias_norm for both datasets (rule-based cleaning and synonym mapping)\n",
    "# - Fuzzy match remaining unmatched, prefer same region/state when available\n",
    "# - Write back matched_facility_id + match_strategy, print progress, safe preview\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"RapidFuzz is required. Install via: pip install rapidfuzz\") from e\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def build_alias_norm(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Robust normalisation to collapse descriptive terms and unify common abbreviations.\"\"\"\n",
    "    if s is None:\n",
    "        return pd.Series([], dtype=\"object\")\n",
    "    x = s.astype(str).str.lower()\n",
    "\n",
    "    # unify accents/punctuation\n",
    "    x = (\n",
    "        x.str.normalize(\"NFKD\")\n",
    "         .str.encode(\"ascii\", \"ignore\").str.decode(\"ascii\")\n",
    "         .str.replace(r\"[^\\w\\s\\-&/]\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "    # common synonym expansions\n",
    "    repl = [\n",
    "        (r\"\\bmt\\b\", \"mount\"),\n",
    "        (r\"\\bst\\b\", \"saint\"),          # st mary -> saint mary\n",
    "        (r\"\\bck\\b\", \"creek\"),\n",
    "        (r\"\\bnth\\b\", \"north\"),\n",
    "        (r\"\\bsth\\b\", \"south\"),\n",
    "        (r\"\\bew\\b\", \"east west\"),      # keep both tokens if used\n",
    "        (r\"\\be\\b\", \"east\"),\n",
    "        (r\"\\bw\\b\", \"west\"),\n",
    "        (r\"\\bn\\b\", \"north\"),\n",
    "        (r\"\\bs\\b\", \"south\"),\n",
    "        (r\"\\bcs ?m\\b\", \"csm\"),\n",
    "        (r\"\\bwf\\b\", \"wind farm\"),\n",
    "        (r\"\\bps\\b\", \"power station\"),\n",
    "    ]\n",
    "    for pat, rep in repl:\n",
    "        x = x.str.replace(pat, rep, regex=True)\n",
    "\n",
    "    # drop descriptive/organisation tokens\n",
    "    DROP_WORDS = (\n",
    "        r\"\\b(power|station|wind|solar|farm|hydro|battery|bess|hub|unit|plant|energy|\"\n",
    "        r\"ps|wf|csm|company|co|pty|ltd|limited|plc|trust|holdings?|project|substation|\"\n",
    "        r\"facility|site|assets?)\\b\"\n",
    "    )\n",
    "    x = x.str.replace(DROP_WORDS, \" \", regex=True)\n",
    "\n",
    "    # unify connectors\n",
    "    x = x.str.replace(r\"[/&\\-]\", \" \", regex=True)\n",
    "\n",
    "    # remove numbers that are standalone (keep if part of name? choose to drop)\n",
    "    x = x.str.replace(r\"\\b\\d+\\b\", \" \", regex=True)\n",
    "\n",
    "    # collapse spaces and trim\n",
    "    x = x.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "    return x\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"(empty)\")\n",
    "        return\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# ---------------- setup ----------------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# guards\n",
    "if \"name_norm\" not in api2.columns or \"name_norm\" not in db2.columns:\n",
    "    raise ValueError(\"Attempt 7 requires 'name_norm' on both api2 and db2.\")\n",
    "\n",
    "# identifier to write to matched_facility_id\n",
    "db_id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 has no identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "api_region_col = _pick_first_existing(api2, [\"region_api\", \"region\"])\n",
    "db_region_col  = _pick_first_existing(db2,  [\"region_db\", \"region\"])\n",
    "api_state_col  = _pick_first_existing(api2, [\"state_code\", \"state\"])\n",
    "db_state_col   = _pick_first_existing(db2,  [\"state_code\", \"state\"])\n",
    "use_region = api_region_col is not None and db_region_col is not None\n",
    "use_state  = api_state_col is not None and db_state_col is not None\n",
    "\n",
    "# parameters\n",
    "FUZZ_THRESHOLD = 88\n",
    "SCORER = fuzz.token_set_ratio\n",
    "STRATEGY_LABEL = f\"alias_fuzzy_tokenset_{FUZZ_THRESHOLD}\"\n",
    "\n",
    "print(f\"[Attempt 7] Identifier: '{CHOSEN_DB_ID_COL}'. Threshold ≥ {FUZZ_THRESHOLD}. \"\n",
    "      f\"Prefer region: {use_region}, state: {use_state}\")\n",
    "\n",
    "# ---------------- build alias_norm ----------------\n",
    "if \"alias_norm\" not in api2.columns:\n",
    "    api2[\"alias_norm\"] = build_alias_norm(api2[\"name_norm\"])\n",
    "if \"alias_norm\" not in db2.columns:\n",
    "    db2[\"alias_norm\"] = build_alias_norm(db2[\"name_norm\"])\n",
    "\n",
    "# candidates: still unmatched and have alias_norm\n",
    "cand = api2[api2[\"matched_facility_id\"].isna() & api2[\"alias_norm\"].notna() & (api2[\"alias_norm\"].str.len() > 0)].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "\n",
    "# db ref\n",
    "db_ref = db2[db2[\"alias_norm\"].notna() & (db2[\"alias_norm\"].str.len() > 0) & db2[CHOSEN_DB_ID_COL].notna()].copy()\n",
    "db_ref[\"__chosen_id\"] = db_ref[CHOSEN_DB_ID_COL].astype(str)\n",
    "if use_region: db_ref[\"__region\"] = db_ref[db_region_col].astype(str)\n",
    "if use_state:  db_ref[\"__state\"] = db_ref[db_state_col].astype(str)\n",
    "\n",
    "accepted_rows, accepted_ids, accepted_scores, accepted_best = [], [], [], []\n",
    "rejected_rows = []\n",
    "\n",
    "def _match_block(block_df: pd.DataFrame, ref_df: pd.DataFrame):\n",
    "    \"\"\"Run fuzzy matching of alias_norm for a block against reference.\"\"\"\n",
    "    if ref_df.empty or block_df.empty:\n",
    "        return [], [], [], [], []\n",
    "    queries = block_df[\"alias_norm\"].astype(str).tolist()\n",
    "    choice_names = ref_df[\"alias_norm\"].astype(str).tolist()\n",
    "    choice_ids   = ref_df[\"__chosen_id\"].tolist()\n",
    "    scores_mat = process.cdist(queries, choice_names, scorer=SCORER, workers=0)\n",
    "    argmax = scores_mat.argmax(axis=1)\n",
    "    scores = scores_mat.max(axis=1)\n",
    "\n",
    "    sel = scores >= FUZZ_THRESHOLD\n",
    "    rows  = block_df[\"index_api\"].to_numpy()[sel].tolist()\n",
    "    ids   = np.array(choice_ids)[argmax][sel].tolist()\n",
    "    sc    = scores[sel].astype(float).tolist()\n",
    "    bestn = np.array(choice_names)[argmax][sel].tolist()\n",
    "\n",
    "    rej_rows = block_df[\"index_api\"].to_numpy()[~sel].tolist()\n",
    "    return rows, ids, sc, bestn, rej_rows\n",
    "\n",
    "# Priority 1: within same region (if available)\n",
    "if use_region:\n",
    "    for rg, g in cand.groupby(cand[api_region_col].astype(str)):\n",
    "        ref = db_ref[db_ref[\"__region\"] == str(rg)]\n",
    "        rows, ids, sc, bestn, rej = _match_block(g, ref)\n",
    "        accepted_rows += rows; accepted_ids += ids; accepted_scores += sc; accepted_best += bestn\n",
    "        rejected_rows += rej\n",
    "\n",
    "# Priority 2: fallback within same state (if available and not already matched here)\n",
    "if use_state:\n",
    "    remain = cand[~cand[\"index_api\"].isin(accepted_rows)].copy()\n",
    "    for st, g in remain.groupby(remain[api_state_col].astype(str)):\n",
    "        ref = db_ref[db_ref[\"__state\"] == str(st)]\n",
    "        rows, ids, sc, bestn, rej = _match_block(g, ref)\n",
    "        # avoid duplicating acceptance for the same id (keep highest score)\n",
    "        accepted_rows += rows; accepted_ids += ids; accepted_scores += sc; accepted_best += bestn\n",
    "        rejected_rows += rej\n",
    "\n",
    "# Priority 3: global fallback (only for those still not matched)\n",
    "remain = cand[~cand[\"index_api\"].isin(accepted_rows)].copy()\n",
    "rows, ids, sc, bestn, rej = _match_block(remain, db_ref)\n",
    "accepted_rows += rows; accepted_ids += ids; accepted_scores += sc; accepted_best += bestn\n",
    "rejected_rows += rej\n",
    "\n",
    "# One-to-one resolution per chosen_id: keep highest score\n",
    "gain = 0\n",
    "if accepted_rows:\n",
    "    acc_df = pd.DataFrame({\n",
    "        \"index_api\": accepted_rows,\n",
    "        \"__chosen_id\": accepted_ids,\n",
    "        \"__score\": accepted_scores,\n",
    "        \"__best_name\": accepted_best\n",
    "    })\n",
    "    acc_df = acc_df.sort_values([\"__chosen_id\",\"__score\"], ascending=[True, False]).groupby(\"__chosen_id\", as_index=False).first()\n",
    "    gain = len(acc_df)\n",
    "\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_facility_id\"] = acc_df[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"match_strategy\"] = STRATEGY_LABEL\n",
    "\n",
    "print(f\"Alias-fuzzy accepted (>= {FUZZ_THRESHOLD}): {gain}\")\n",
    "_progress(api2, label=\"Attempt 7: alias fuzzy\")\n",
    "\n",
    "# previews\n",
    "if gain > 0:\n",
    "    preview = acc_df.merge(\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[\n",
    "            [\"index_api\",\"facility_name_api\",\"name_norm\",\"alias_norm\"]\n",
    "        ] if \"facility_name_api\" in api2.columns else\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[\n",
    "            [\"index_api\",\"name_norm\",\"alias_norm\"]\n",
    "        ],\n",
    "        on=\"index_api\", how=\"left\"\n",
    "    )\n",
    "    _safe_preview(preview,\n",
    "                  [\"index_api\",\"facility_name_api\",\"name_norm\",\"alias_norm\",\"__best_name\",\"__score\",\"__chosen_id\"],\n",
    "                  n=10, title=\"Accepted (top 10) — Attempt 7\")\n",
    "else:\n",
    "    print(\"No accepted rows to preview.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 8] Using id: facility_code. Base radius = 15.0 km, expanded = 50.0 km.\n",
      "Accepted by geo-expansion: 1\n",
      "[Attempt 8: geo expansion by fuel type] total rows: 514\n",
      "[Attempt 8: geo expansion by fuel type] matched rows: 418\n",
      "[Attempt 8: geo expansion by fuel type] remaining unmatched: 96\n",
      "[Attempt 8: geo expansion by fuel type] progress: 81.32%\n",
      "Accepted (top 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_api</th>\n",
       "      <th>matched_facility_id</th>\n",
       "      <th>matched_distance_km</th>\n",
       "      <th>match_strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>NSW1</td>\n",
       "      <td>281</td>\n",
       "      <td>11.349188</td>\n",
       "      <td>geo_expanded_typeaware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region_api matched_facility_id  matched_distance_km  \\\n",
       "383       NSW1                 281            11.349188   \n",
       "\n",
       "             match_strategy  \n",
       "383  geo_expanded_typeaware  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 8 (robust): Geo expansion by facility type (larger radius for Wind/Solar)\n",
    "# - Fix preview to avoid KeyError when optional columns are missing\n",
    "# - Keep the same matching logic; print progress and safe previews\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE_KM = 15.0\n",
    "EXPANDED_KM = 50.0\n",
    "EARTH_R_KM = 6371.0\n",
    "STRATEGY_LABEL = \"geo_expanded_typeaware\"\n",
    "\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = np.nan\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = np.nan\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(lat1.astype(float)); lon1 = np.radians(lon1.astype(float))\n",
    "    lat2 = np.radians(lat2.astype(float)); lon2 = np.radians(lon2.astype(float))\n",
    "    dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*(np.sin(dlon/2.0)**2)\n",
    "    return EARTH_R_KM * 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"(empty)\")\n",
    "        return\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# ---------- setup ----------\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "api_lat_col = _pick_first_existing(api2, [\"lat_api\",\"latitude\",\"lat\"])\n",
    "api_lon_col = _pick_first_existing(api2, [\"lng_api\",\"longitude\",\"lon\",\"long\"])\n",
    "db_lat_col  = _pick_first_existing(db2,  [\"latitude\",\"lat\"])\n",
    "db_lon_col  = _pick_first_existing(db2,  [\"longitude\",\"lon\",\"long\"])\n",
    "api_region_col = _pick_first_existing(api2, [\"region_api\",\"region\"])\n",
    "db_region_col  = _pick_first_existing(db2,  [\"region_db\",\"region\"])\n",
    "api_state_col  = _pick_first_existing(api2, [\"state_code\",\"state\"])\n",
    "db_state_col   = _pick_first_existing(db2,  [\"state_code\",\"state\"])\n",
    "\n",
    "id_candidates = [c for c in [\"facility_id\",\"facility_code\",\"facility_name\"] if c in db2.columns]\n",
    "if not id_candidates:\n",
    "    raise ValueError(\"db2 has no identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = id_candidates[0]\n",
    "\n",
    "print(f\"[Attempt 8] Using id: {CHOSEN_DB_ID_COL}. Base radius = {BASE_KM} km, expanded = {EXPANDED_KM} km.\")\n",
    "\n",
    "# Candidates: still unmatched + have coords\n",
    "cand = api2[(api2[\"matched_facility_id\"].isna()) &\n",
    "            api2[api_lat_col].notna() & api2[api_lon_col].notna()].copy()\n",
    "\n",
    "# Ensure we have a fuel_type column to test (fallback to empty string)\n",
    "if \"fuel_type\" not in cand.columns:\n",
    "    cand[\"fuel_type\"] = \"\"\n",
    "\n",
    "db_ref = db2[(db2[CHOSEN_DB_ID_COL].notna()) &\n",
    "             db2[db_lat_col].notna() & db2[db_lon_col].notna()].copy()\n",
    "\n",
    "accepted_rows, accepted_ids, accepted_dists = [], [], []\n",
    "\n",
    "for idx, row in cand.iterrows():\n",
    "    lat1, lon1 = float(row[api_lat_col]), float(row[api_lon_col])\n",
    "    ftype = str(row[\"fuel_type\"]).lower()\n",
    "    radius = EXPANDED_KM if any(k in ftype for k in [\"wind\", \"solar\"]) else BASE_KM\n",
    "\n",
    "    # Prefer region match, otherwise fall back to state if available\n",
    "    ref = db_ref\n",
    "    if api_region_col and db_region_col and pd.notna(row.get(api_region_col, np.nan)):\n",
    "        ref = ref[ref[db_region_col] == row[api_region_col]]\n",
    "    elif api_state_col and db_state_col and pd.notna(row.get(api_state_col, np.nan)):\n",
    "        ref = ref[ref[db_state_col] == row[api_state_col]]\n",
    "\n",
    "    if ref.empty:\n",
    "        continue\n",
    "\n",
    "    dists = _haversine_km(\n",
    "        np.full(len(ref), lat1),\n",
    "        np.full(len(ref), lon1),\n",
    "        ref[db_lat_col].to_numpy(),\n",
    "        ref[db_lon_col].to_numpy()\n",
    "    )\n",
    "    j = int(np.argmin(dists))\n",
    "    dist_best = float(dists[j])\n",
    "\n",
    "    if dist_best <= radius:\n",
    "        accepted_rows.append(idx)\n",
    "        accepted_ids.append(str(ref.iloc[j][CHOSEN_DB_ID_COL]))\n",
    "        accepted_dists.append(dist_best)\n",
    "\n",
    "# Write back\n",
    "if accepted_rows:\n",
    "    api2.loc[accepted_rows, \"matched_facility_id\"] = accepted_ids\n",
    "    api2.loc[accepted_rows, \"match_strategy\"] = STRATEGY_LABEL\n",
    "    if \"matched_distance_km\" not in api2.columns:\n",
    "        api2[\"matched_distance_km\"] = np.nan\n",
    "    api2.loc[accepted_rows, \"matched_distance_km\"] = accepted_dists\n",
    "    print(f\"Accepted by geo-expansion: {len(accepted_rows)}\")\n",
    "else:\n",
    "    print(\"No additional matches found via geo-expansion.\")\n",
    "\n",
    "# Progress + robust previews (select columns inside the function)\n",
    "_progress(api2, \"Attempt 8: geo expansion by fuel type\")\n",
    "preview_df = api2.loc[accepted_rows].copy() if accepted_rows else pd.DataFrame()\n",
    "_safe_preview(\n",
    "    preview_df,\n",
    "    desired_cols=[api_region_col, \"fuel_type\", \"matched_facility_id\", \"matched_distance_km\", \"match_strategy\"],\n",
    "    n=10,\n",
    "    title=\"Accepted (top 10)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Attempt 9r] ID='facility_code', fuzzy≥80, geo≤35.0 km, state gate: OFF, fuel gate: OFF\n",
      "Relaxed-fuzzy accepted (retry): 0\n",
      "[Attempt 9r: relaxed fuzzy + gates] total rows: 514\n",
      "[Attempt 9r: relaxed fuzzy + gates] matched rows: 418\n",
      "[Attempt 9r: relaxed fuzzy + gates] remaining unmatched: 96\n",
      "[Attempt 9r: relaxed fuzzy + gates] progress: 81.32%\n",
      "No accepted rows to preview.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rengga\\AppData\\Local\\Temp\\ipykernel_19628\\4138642062.py:47: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return EARTH_R_KM * 2.0 * _N.arctan2(_N.sqrt(a), _N.sqrt(1.0 - a))\n"
     ]
    }
   ],
   "source": [
    "# Attempt 9: Relaxed fuzzy within state + same fuel_category + geo gate (robust numpy alias)\n",
    "# Uses local numpy alias ⁠ _N ⁠ inside haversine to avoid collisions with any variable named ⁠ np ⁠.\n",
    "\n",
    "import numpy as _N\n",
    "import pandas as pd\n",
    "import numpy as np  # keep existing alias but haversine will NOT rely on it\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# ---- parameters ----\n",
    "FUZZ_THRESHOLD = 80\n",
    "MAX_KM = 35.0\n",
    "EARTH_R_KM = 6371.0\n",
    "STRATEGY_LABEL = f\"relaxed_fuzzy_state_fuel_geo_{FUZZ_THRESHOLD}_{int(MAX_KM)}km\"\n",
    "\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([_N.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([_N.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df: pd.DataFrame, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Use local numpy alias to avoid np-collision in user namespace.\"\"\"\n",
    "    lat1 = _N.radians(_N.asarray(lat1, dtype=float))\n",
    "    lon1 = _N.radians(_N.asarray(lon1, dtype=float))\n",
    "    lat2 = _N.radians(_N.asarray(lat2, dtype=float))\n",
    "    lon2 = _N.radians(_N.asarray(lon2, dtype=float))\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = _N.sin(dlat/2.0)*2 + _N.cos(lat1) * _N.cos(lat2) * (_N.sin(dlon/2.0)*2)\n",
    "    return EARTH_R_KM * 2.0 * _N.arctan2(_N.sqrt(a), _N.sqrt(1.0 - a))\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"(empty)\")\n",
    "        return\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# ---- setup ----\n",
    "api2 = _ensure_match_columns(api2)\n",
    "if \"name_norm\" not in api2.columns or \"name_norm\" not in db2.columns:\n",
    "    raise ValueError(\"Attempt 9r requires 'name_norm' on both api2 and db2.\")\n",
    "\n",
    "db_id_candidates = [c for c in [\"facility_id\",\"facility_code\",\"facility_name\"] if c in db2.columns]\n",
    "if not db_id_candidates:\n",
    "    raise ValueError(\"db2 has no identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = db_id_candidates[0]\n",
    "\n",
    "api_state_col  = _pick_first_existing(api2, [\"state_code\",\"state\"])\n",
    "db_state_col   = _pick_first_existing(db2,  [\"state_code\",\"state\"])\n",
    "use_state_gate = api_state_col is not None and db_state_col is not None\n",
    "\n",
    "api_lat_col = _pick_first_existing(api2, [\"lat_api\",\"latitude\",\"lat\"])\n",
    "api_lon_col = _pick_first_existing(api2, [\"lng_api\",\"longitude\",\"lon\",\"long\"])\n",
    "db_lat_col  = _pick_first_existing(db2,  [\"latitude\",\"lat\"])\n",
    "db_lon_col  = _pick_first_existing(db2,  [\"longitude\",\"lon\",\"long\"])\n",
    "for nm, col in [(\"api_lat\",api_lat_col),(\"api_lon\",api_lon_col),(\"db_lat\",db_lat_col),(\"db_lon\",db_lon_col)]:\n",
    "    if col is None:\n",
    "        raise ValueError(f\"Attempt 9r needs coordinate column: {nm}\")\n",
    "\n",
    "api_fuel_cat = _pick_first_existing(api2, [\"fuel_category\",\"fuel_cat\",\"fuel_group\"])\n",
    "db_fuel_cat  = _pick_first_existing(db2,  [\"fuel_category\",\"fuel_cat\",\"fuel_group\"])\n",
    "use_fuel_gate = api_fuel_cat is not None and db_fuel_cat is not None\n",
    "\n",
    "print(f\"[Attempt 9r] ID='{CHOSEN_DB_ID_COL}', fuzzy≥{FUZZ_THRESHOLD}, geo≤{MAX_KM} km, \"\n",
    "      f\"state gate: {'ON' if use_state_gate else 'OFF'}, fuel gate: {'ON' if use_fuel_gate else 'OFF'}\")\n",
    "\n",
    "# ---- candidates ----\n",
    "cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "cand = cand[cand[\"name_norm\"].notna() & cand[api_lat_col].notna() & cand[api_lon_col].notna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\":\"index_api\"})\n",
    "\n",
    "db_ref = db2.copy()\n",
    "db_ref = db_ref[db_ref[\"name_norm\"].notna() & db_ref[CHOSEN_DB_ID_COL].notna() &\n",
    "                db_ref[db_lat_col].notna() & db_ref[db_lon_col].notna()].copy()\n",
    "if use_state_gate: db_ref[\"__state\"] = db_ref[db_state_col].astype(str)\n",
    "if use_fuel_gate:  db_ref[\"__fuel\"]  = db_ref[db_fuel_cat].astype(str)\n",
    "db_ref[\"__chosen_id\"] = db_ref[CHOSEN_DB_ID_COL].astype(str)\n",
    "\n",
    "accepted_rows, accepted_ids, accepted_scores, accepted_dists, accepted_best = [], [], [], [], []\n",
    "rejected_rows = []\n",
    "\n",
    "scorer = fuzz.token_sort_ratio\n",
    "\n",
    "if use_state_gate:\n",
    "    groups = cand.groupby(cand[api_state_col].astype(str))\n",
    "else:\n",
    "    groups = [(\"ALL\", cand)]\n",
    "\n",
    "for grp_key, g in groups:\n",
    "    ref_state = db_ref if not use_state_gate else db_ref[db_ref[\"__state\"] == str(grp_key)]\n",
    "    if ref_state.empty:\n",
    "        continue\n",
    "\n",
    "    if use_fuel_gate:\n",
    "        for fuel, g2 in g.groupby(g[api_fuel_cat].astype(str)):\n",
    "            ref = ref_state[ref_state[\"__fuel\"] == str(fuel)]\n",
    "            if ref.empty:\n",
    "                continue\n",
    "\n",
    "            qnames = g2[\"name_norm\"].astype(str).tolist()\n",
    "            choice_names = ref[\"name_norm\"].astype(str).tolist()\n",
    "            choice_ids   = ref[\"__chosen_id\"].tolist()\n",
    "            lat_db, lon_db = ref[db_lat_col].astype(float).to_numpy(), ref[db_lon_col].astype(float).to_numpy()\n",
    "\n",
    "            scores_mat = process.cdist(qnames, choice_names, scorer=scorer, workers=0)\n",
    "            argmax = scores_mat.argmax(axis=1)\n",
    "            scores = scores_mat.max(axis=1)\n",
    "\n",
    "            lat_api = g2[api_lat_col].astype(float).to_numpy()\n",
    "            lon_api = g2[api_lon_col].astype(float).to_numpy()\n",
    "            best_lat = lat_db[argmax]; best_lon = lon_db[argmax]\n",
    "            dists = _haversine_km(lat_api, lon_api, best_lat, best_lon)\n",
    "\n",
    "            sel = (scores >= FUZZ_THRESHOLD) & (dists <= MAX_KM)\n",
    "            if sel.any():\n",
    "                accepted_rows.extend(g2[\"index_api\"].to_numpy()[sel].tolist())\n",
    "                accepted_ids.extend(_N.array(choice_ids)[argmax][sel].tolist())\n",
    "                accepted_scores.extend(scores[sel].astype(float).tolist())\n",
    "                accepted_dists.extend(dists[sel].astype(float).tolist())\n",
    "                accepted_best.extend(_N.array(choice_names)[argmax][sel].tolist())\n",
    "\n",
    "            rejected_rows.extend(g2[\"index_api\"].to_numpy()[~sel].tolist())\n",
    "    else:\n",
    "        qnames = g[\"name_norm\"].astype(str).tolist()\n",
    "        choice_names = ref_state[\"name_norm\"].astype(str).tolist()\n",
    "        choice_ids   = ref_state[\"__chosen_id\"].tolist()\n",
    "        lat_db, lon_db = ref_state[db_lat_col].astype(float).to_numpy(), ref_state[db_lon_col].astype(float).to_numpy()\n",
    "\n",
    "        scores_mat = process.cdist(qnames, choice_names, scorer=scorer, workers=0)\n",
    "        argmax = scores_mat.argmax(axis=1)\n",
    "        scores = scores_mat.max(axis=1)\n",
    "\n",
    "        lat_api = g[api_lat_col].astype(float).to_numpy()\n",
    "        lon_api = g[api_lon_col].astype(float).to_numpy()\n",
    "        best_lat = lat_db[argmax]; best_lon = lon_db[argmax]\n",
    "        dists = _haversine_km(lat_api, lon_api, best_lat, best_lon)\n",
    "\n",
    "        sel = (scores >= FUZZ_THRESHOLD) & (dists <= MAX_KM)\n",
    "        if sel.any():\n",
    "            accepted_rows.extend(g[\"index_api\"].to_numpy()[sel].tolist())\n",
    "            accepted_ids.extend(_N.array(choice_ids)[argmax][sel].tolist())\n",
    "            accepted_scores.extend(scores[sel].astype(float).tolist())\n",
    "            accepted_dists.extend(dists[sel].astype(float).tolist())\n",
    "            accepted_best.extend(_N.array(choice_names)[argmax][sel].tolist())\n",
    "\n",
    "        rejected_rows.extend(g[\"index_api\"].to_numpy()[~sel].tolist())\n",
    "\n",
    "# one-to-one resolution\n",
    "gain = 0\n",
    "if accepted_rows:\n",
    "    acc_df = pd.DataFrame({\n",
    "        \"index_api\": accepted_rows,\n",
    "        \"__chosen_id\": accepted_ids,\n",
    "        \"__score\": accepted_scores,\n",
    "        \"__dist_km\": accepted_dists,\n",
    "        \"__best_name\": accepted_best\n",
    "    })\n",
    "    acc_df = acc_df.sort_values([\"__chosen_id\",\"__score\",\"__dist_km\"], ascending=[True, False, True])\n",
    "    acc_df = acc_df.groupby(\"__chosen_id\", as_index=False).first()\n",
    "    gain = len(acc_df)\n",
    "\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_facility_id\"] = acc_df[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"match_strategy\"] = STRATEGY_LABEL\n",
    "    if \"matched_distance_km\" not in api2.columns:\n",
    "        api2[\"matched_distance_km\"] = _N.nan\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_distance_km\"] = acc_df[\"__dist_km\"].astype(float).values\n",
    "\n",
    "print(f\"Relaxed-fuzzy accepted (retry): {gain}\")\n",
    "_progress(api2, label=\"Attempt 9r: relaxed fuzzy + gates\")\n",
    "\n",
    "# preview (robust)\n",
    "if gain > 0:\n",
    "    preview = acc_df.merge(\n",
    "        api2.reset_index().rename(columns={\"index\":\"index_api\"})[\n",
    "            [c for c in [\"index_api\",\"facility_name_api\",\"name_norm\", api_state_col, api_fuel_cat] if c]\n",
    "        ],\n",
    "        on=\"index_api\", how=\"left\"\n",
    "    )\n",
    "    _safe_preview(preview,\n",
    "                  desired_cols=[c for c in [\"index_api\",\"facility_name_api\",\"name_norm\",\"__best_name\",\n",
    "                                            \"__score\",\"__dist_km\",\"__chosen_id\"] if True],\n",
    "                  n=10, title=\"Accepted (top 10) — Attempt 9r\")\n",
    "else:\n",
    "    print(\"No accepted rows to preview.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted (top 10) — Attempt 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>__chosen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>Eildon</td>\n",
       "      <td>eildon</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>Lake Bonney 3</td>\n",
       "      <td>lake bonney 3</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>495</td>\n",
       "      <td>Woodlawn</td>\n",
       "      <td>woodlawn</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>254</td>\n",
       "      <td>Loy Yang A</td>\n",
       "      <td>loy yang a</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>Bell Bay</td>\n",
       "      <td>bell bay</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>224</td>\n",
       "      <td>Kidston</td>\n",
       "      <td>kidston</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>193</td>\n",
       "      <td>Hornsdale 2</td>\n",
       "      <td>hornsdale 2</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>146</td>\n",
       "      <td>Gannawarra</td>\n",
       "      <td>gannawarra</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>316</td>\n",
       "      <td>Oakey 2</td>\n",
       "      <td>oakey 2</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156</td>\n",
       "      <td>Glenrowan West</td>\n",
       "      <td>glenrowan west</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api   facility_name       name_norm __chosen_id\n",
       "0        131          Eildon          eildon          12\n",
       "1        235   Lake Bonney 3   lake bonney 3         218\n",
       "2        495        Woodlawn        woodlawn         219\n",
       "3        254      Loy Yang A      loy yang a          23\n",
       "4         25        Bell Bay        bell bay         369\n",
       "5        224         Kidston         kidston         493\n",
       "6        193     Hornsdale 2     hornsdale 2         506\n",
       "7        146      Gannawarra      gannawarra         609\n",
       "8        316         Oakey 2         oakey 2         616\n",
       "9        156  Glenrowan West  glenrowan west         645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This does not change matching results, only re-renders the preview\n",
    "\n",
    "# guard: acc_df is created in Attempt 10 when gain > 0\n",
    "if 'acc_df' in globals() and isinstance(acc_df, pd.DataFrame) and not acc_df.empty:\n",
    "    api2_with_idx = api2.reset_index().rename(columns={\"index\":\"index_api\"})\n",
    "    # choose only columns that actually exist in api2\n",
    "    preview_cols = [c for c in [\"index_api\", \"facility_name_api\", \"facility_name\", \"name_norm\", api_state_col]\n",
    "                    if c and c in api2_with_idx.columns]\n",
    "\n",
    "    preview = acc_df.merge(\n",
    "        api2_with_idx[preview_cols],\n",
    "        on=\"index_api\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # desired columns (with safe membership check)\n",
    "    desired_cols = [c for c in [\"index_api\", \"facility_name_api\", \"facility_name\",\n",
    "                                \"name_norm\", \"__overlap\", \"__dist_km\", \"__chosen_id\"]\n",
    "                    if c in preview.columns]\n",
    "\n",
    "    print(\"Accepted (top 10) — Attempt 10\")\n",
    "    display(preview[desired_cols].head(10) if desired_cols else preview.head(10))\n",
    "else:\n",
    "    print(\"No accepted rows to preview (acc_df missing or empty).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-overlap accepted in this attempt: 10\n",
      "[Attempt 10: token-overlap + geo] total rows: 514\n",
      "[Attempt 10: token-overlap + geo] matched rows: 428\n",
      "[Attempt 10: token-overlap + geo] remaining unmatched: 86\n",
      "[Attempt 10: token-overlap + geo] progress: 83.27%\n",
      "Accepted (top 10) — Attempt 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_api</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>name_norm</th>\n",
       "      <th>__overlap</th>\n",
       "      <th>__dist_km</th>\n",
       "      <th>__chosen_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227</td>\n",
       "      <td>Kogan Creek</td>\n",
       "      <td>kogan creek</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>478</td>\n",
       "      <td>Whitwood Road</td>\n",
       "      <td>whitwood road</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>Swanbank E</td>\n",
       "      <td>swanbank e</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>Mugga Lane</td>\n",
       "      <td>mugga lane</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341</td>\n",
       "      <td>Quorn Park</td>\n",
       "      <td>quorn park</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>485</td>\n",
       "      <td>Windy Hill</td>\n",
       "      <td>windy hill</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>458</td>\n",
       "      <td>Waratah Super Battery</td>\n",
       "      <td>waratah super battery</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>327</td>\n",
       "      <td>Phillip Island</td>\n",
       "      <td>phillip island</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>203</td>\n",
       "      <td>Invicta Sugar Mill</td>\n",
       "      <td>invicta sugar mill</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>138</td>\n",
       "      <td>Eraring 2</td>\n",
       "      <td>eraring 2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_api          facility_name              name_norm  __overlap  \\\n",
       "0        227            Kogan Creek            kogan creek   0.333333   \n",
       "1        478          Whitwood Road          whitwood road   0.250000   \n",
       "2        402             Swanbank E             swanbank e   0.250000   \n",
       "3        299             Mugga Lane             mugga lane   0.250000   \n",
       "4        341             Quorn Park             quorn park   0.250000   \n",
       "5        485             Windy Hill             windy hill   0.200000   \n",
       "6        458  Waratah Super Battery  waratah super battery   0.200000   \n",
       "7        327         Phillip Island         phillip island   0.333333   \n",
       "8        203     Invicta Sugar Mill     invicta sugar mill   0.333333   \n",
       "9        138              Eraring 2              eraring 2   0.250000   \n",
       "\n",
       "   __dist_km __chosen_id  \n",
       "0        0.0         138  \n",
       "1        0.0         141  \n",
       "2        0.0         240  \n",
       "3        0.0         253  \n",
       "4        0.0         260  \n",
       "5        0.0          28  \n",
       "6        0.0         698  \n",
       "7        0.0         755  \n",
       "8        0.0         787  \n",
       "9        0.0         799  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attempt 10 (clean retry): Token-overlap (Jaccard) + geographic gate (<= 35 km), prefer same state\n",
    "# Runs only on currently-unmatched rows, writes matched_facility_id and match_strategy, and prints progress.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ----- parameters -----\n",
    "MAX_KM = 35.0\n",
    "EARTH_R_KM = 6371.0\n",
    "STRATEGY_LABEL = f\"token_overlap_geo_{int(MAX_KM)}km\"\n",
    "\n",
    "# ----- helpers -----\n",
    "def _ensure_match_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"matched_facility_id\" not in df.columns:\n",
    "        df[\"matched_facility_id\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    if \"match_strategy\" not in df.columns:\n",
    "        df[\"match_strategy\"] = pd.Series([np.nan] * len(df), dtype=\"object\")\n",
    "    return df\n",
    "\n",
    "def _progress(a2: pd.DataFrame, label: str):\n",
    "    total = len(a2)\n",
    "    matched = a2[\"matched_facility_id\"].notna().sum()\n",
    "    remaining = total - matched\n",
    "    pct = (matched / total * 100.0) if total else 0.0\n",
    "    print(f\"[{label}] total rows: {total}\")\n",
    "    print(f\"[{label}] matched rows: {matched}\")\n",
    "    print(f\"[{label}] remaining unmatched: {remaining}\")\n",
    "    print(f\"[{label}] progress: {pct:.2f}%\")\n",
    "\n",
    "def _pick_first_existing(df, options):\n",
    "    for c in options:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(np.asarray(lat1, dtype=\"float64\"))\n",
    "    lon1 = np.radians(np.asarray(lon1, dtype=\"float64\"))\n",
    "    lat2 = np.radians(np.asarray(lat2, dtype=\"float64\"))\n",
    "    lon2 = np.radians(np.asarray(lon2, dtype=\"float64\"))\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)*2 + np.cos(lat1) * np.cos(lat2) * (np.sin(dlon/2.0)*2)\n",
    "    a = np.clip(a, 0.0, 1.0)  # numerical safety\n",
    "    return EARTH_R_KM * 2.0 * np.arctan2(np.sqrt(a), np.sqrt(1.0 - a))\n",
    "\n",
    "TOKEN_RX = re.compile(r\"[a-z]+\")\n",
    "\n",
    "def tokens(s: str):\n",
    "    if not isinstance(s, str):\n",
    "        return set()\n",
    "    return set(TOKEN_RX.findall(s.lower()))\n",
    "\n",
    "def jaccard(a: set, b: set) -> float:\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def _safe_preview(df, desired_cols, n=10, title=None):\n",
    "    if title: print(title)\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"(empty)\")\n",
    "        return\n",
    "    cols = [c for c in desired_cols if c in df.columns]\n",
    "    display(df[cols].head(n) if cols else df.head(n))\n",
    "\n",
    "# ----- setup columns -----\n",
    "api2 = _ensure_match_columns(api2)\n",
    "\n",
    "# name field must exist on both\n",
    "if \"name_norm\" not in api2.columns or \"name_norm\" not in db2.columns:\n",
    "    raise ValueError(\"Attempt 10 requires 'name_norm' on both api2 and db2.\")\n",
    "\n",
    "# choose identifier column from db2 to write back\n",
    "id_candidates = [c for c in [\"facility_id\", \"facility_code\", \"facility_name\"] if c in db2.columns]\n",
    "if not id_candidates:\n",
    "    raise ValueError(\"db2 needs an identifier column (facility_id / facility_code / facility_name).\")\n",
    "CHOSEN_DB_ID_COL = id_candidates[0]\n",
    "\n",
    "# coordinates\n",
    "api_lat_col = _pick_first_existing(api2, [\"lat_api\", \"latitude\", \"lat\"])\n",
    "api_lon_col = _pick_first_existing(api2, [\"lng_api\", \"longitude\", \"lon\", \"long\"])\n",
    "db_lat_col  = _pick_first_existing(db2,  [\"latitude\", \"lat\"])\n",
    "db_lon_col  = _pick_first_existing(db2,  [\"longitude\", \"lon\", \"long\"])\n",
    "for nm, col in [(\"api_lat\", api_lat_col), (\"api_lon\", api_lon_col), (\"db_lat\", db_lat_col), (\"db_lon\", db_lon_col)]:\n",
    "    if col is None:\n",
    "        raise ValueError(f\"Attempt 10 needs coordinate column: {nm}\")\n",
    "\n",
    "# optional state gate\n",
    "api_state_col = _pick_first_existing(api2, [\"state_code\", \"state\"])\n",
    "db_state_col  = _pick_first_existing(db2,  [\"state_code\", \"state\"])\n",
    "use_state = api_state_col is not None and db_state_col is not None\n",
    "\n",
    "# ----- build token caches -----\n",
    "api2[\"_tok\"] = api2[\"name_norm\"].apply(tokens)\n",
    "db2[\"_tok\"]  = db2[\"name_norm\"].apply(tokens)\n",
    "\n",
    "# ----- candidate subsets -----\n",
    "cand = api2[api2[\"matched_facility_id\"].isna()].copy()\n",
    "cand = cand[cand[\"_tok\"].apply(len) > 0]\n",
    "cand = cand[cand[api_lat_col].notna() & cand[api_lon_col].notna()].copy()\n",
    "cand = cand.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "\n",
    "db_ref = db2.copy()\n",
    "db_ref = db_ref[db_ref[\"_tok\"].apply(len) > 0]\n",
    "db_ref = db_ref[db_ref[CHOSEN_DB_ID_COL].notna() & db_ref[db_lat_col].notna() & db_ref[db_lon_col].notna()].copy()\n",
    "db_ref[\"__chosen_id\"] = db_ref[CHOSEN_DB_ID_COL].astype(str)\n",
    "if use_state:\n",
    "    db_ref[\"__state\"] = db_ref[db_state_col].astype(str)\n",
    "\n",
    "# ----- main loop -----\n",
    "accepted = []\n",
    "\n",
    "for _, row in cand.iterrows():\n",
    "    pool = db_ref\n",
    "    # prefer same state if available\n",
    "    if use_state and pd.notna(row.get(api_state_col, np.nan)):\n",
    "        pool = pool[pool[\"__state\"] == str(row[api_state_col])]\n",
    "        if pool.empty:\n",
    "            pool = db_ref  # fallback to global pool\n",
    "\n",
    "    if pool.empty:\n",
    "        continue\n",
    "\n",
    "    a_tok = row[\"_tok\"]\n",
    "    # compute jaccard to all pool rows\n",
    "    scores = np.array([jaccard(a_tok, b) for b in pool[\"_tok\"].tolist()], dtype=\"float64\")\n",
    "    if scores.size == 0 or float(np.nanmax(scores)) <= 0.0:\n",
    "        continue\n",
    "\n",
    "    k = int(np.nanargmax(scores))\n",
    "    best = pool.iloc[k]\n",
    "    best_score = float(scores[k])\n",
    "\n",
    "    # distance gate\n",
    "    d_km = float(_haversine_km(\n",
    "        np.array([row[api_lat_col]]), np.array([row[api_lon_col]]),\n",
    "        np.array([best[db_lat_col]]),  np.array([best[db_lon_col]])\n",
    "    )[0])\n",
    "\n",
    "    if d_km <= MAX_KM and best_score > 0.0:\n",
    "        accepted.append((\n",
    "            row[\"index_api\"], str(best[\"__chosen_id\"]), best_score, d_km\n",
    "        ))\n",
    "\n",
    "# ----- write back & report -----\n",
    "gain = 0\n",
    "if accepted:\n",
    "    acc_df = pd.DataFrame(accepted, columns=[\"index_api\", \"__chosen_id\", \"__overlap\", \"__dist_km\"])\n",
    "    # one-to-one on id: highest overlap then nearest\n",
    "    acc_df = acc_df.sort_values([\"__chosen_id\", \"__overlap\", \"__dist_km\"], ascending=[True, False, True])\n",
    "    acc_df = acc_df.groupby(\"__chosen_id\", as_index=False).first()\n",
    "    gain = len(acc_df)\n",
    "\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_facility_id\"] = acc_df[\"__chosen_id\"].astype(str).values\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"match_strategy\"] = STRATEGY_LABEL\n",
    "    if \"matched_distance_km\" not in api2.columns:\n",
    "        api2[\"matched_distance_km\"] = np.nan\n",
    "    api2.loc[acc_df[\"index_api\"].values, \"matched_distance_km\"] = acc_df[\"__dist_km\"].astype(float).values\n",
    "\n",
    "print(f\"Token-overlap accepted in this attempt: {gain}\")\n",
    "_progress(api2, label=\"Attempt 10: token-overlap + geo\")\n",
    "\n",
    "# ----- safe preview -----\n",
    "if gain > 0:\n",
    "    api2_with_idx = api2.reset_index().rename(columns={\"index\": \"index_api\"})\n",
    "    preview_cols = [c for c in [\"index_api\", \"facility_name_api\", \"facility_name\", \"name_norm\", api_state_col] if c in api2_with_idx.columns]\n",
    "    preview = acc_df.merge(api2_with_idx[preview_cols], on=\"index_api\", how=\"left\")\n",
    "    desired_cols = [c for c in [\"index_api\", \"facility_name_api\", \"facility_name\", \"name_norm\", \"__overlap\", \"__dist_km\", \"__chosen_id\"] if c in preview.columns]\n",
    "    _safe_preview(preview, desired_cols, n=10, title=\"Accepted (top 10) — Attempt 10\")\n",
    "else:\n",
    "    print(\"No accepted rows to preview.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> <span style=\"color:pink\">1.2 Get All Power Generated and CO2 Emissions per Facility</span></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facility data will return total data instead of facility specific data if we do not specify the facility code in tha API call. Hence, we need to pass the facility code we get from previous API call to this endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total facilities: 514\n"
     ]
    }
   ],
   "source": [
    "# get all facility code\n",
    "FACILITY_LIST = facilities_df[\"code\"].tolist()\n",
    "print(f\"Total facilities: {len(FACILITY_LIST)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since the parameter only accept 30 max characters and we have more than 500 facilities, passing all facility code at once will result in error. To get around that, we will use the batching strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"./DATA/EXTRACTED\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "ENDPOINT = \"data/facilities/NEM\"\n",
    "batch_size = 5\n",
    "\n",
    "# function chunk the facility code list into batches\n",
    "def chunk_list(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n], i, min(i+n, len(lst))  \n",
    "\n",
    "# batch retrieval\n",
    "def batch_retrieval(batch_size:int):\n",
    "    for batch, start, end in chunk_list(FACILITY_LIST, batch_size):\n",
    "        batch_id = math.ceil(end/batch_size)\n",
    "        cache_path = os.path.join(OUT_DIR, f\"batch_{start+1:04d}_{end:04d}.json\")\n",
    "\n",
    "        if os.path.exists(cache_path):\n",
    "            print(f\"Batch {batch_id}: {start+1}-{end} already cached.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching batch {batch_id}: facilities {start+1}–{end} ({batch})\")\n",
    "\n",
    "        # params\n",
    "        params = {\n",
    "            'network_code': 'NEM',\n",
    "            'metrics': {'power', 'emissions'},\n",
    "            'interval': '5m',\n",
    "            \"date_start\": \"2025-10-01\",\n",
    "            \"date_end\": \"2025-10-08\",\n",
    "            \"facility_code\": {f for f in batch},\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            r = requests.get(f\"{BASE_URL}{ENDPOINT}\", headers=HEADERS, params=params, timeout=90)\n",
    "            if r.status_code == 200:\n",
    "                payload = r.json()\n",
    "                with open(cache_path, \"w\") as f:\n",
    "                    json.dump(payload, f, indent=2)\n",
    "                print(f\"Saved {cache_path}\")\n",
    "            else:\n",
    "                print(f\"HTTP {r.status_code}: {r.text[:150]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch {batch_id}: {e}\")\n",
    "\n",
    "        time.sleep(0.3)\n",
    "\n",
    "# function to flatten the payload\n",
    "def flatten(payload):\n",
    "    rows = []\n",
    "    for block in payload.get(\"data\", []):\n",
    "        metric   = block.get(\"metric\")\n",
    "        unit     = block.get(\"unit\")\n",
    "        interval = block.get(\"interval\")\n",
    "        for res in block.get(\"results\", []):\n",
    "            unit_code = (res.get(\"columns\") or {}).get(\"unit_code\")\n",
    "            for ts, val in res.get(\"data\", []):\n",
    "                rows.append({\"timestamp\": ts, \"unit_code\": unit_code,\n",
    "                            \"metric\": metric, \"interval\": interval, \"unit\": unit, \"value\": val})\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 1-5 already cached.\n",
      "Batch 2: 6-10 already cached.\n",
      "Batch 3: 11-15 already cached.\n",
      "Batch 4: 16-20 already cached.\n",
      "Batch 5: 21-25 already cached.\n",
      "Batch 6: 26-30 already cached.\n",
      "Batch 7: 31-35 already cached.\n",
      "Batch 8: 36-40 already cached.\n",
      "Batch 9: 41-45 already cached.\n",
      "Batch 10: 46-50 already cached.\n",
      "Batch 11: 51-55 already cached.\n",
      "Batch 12: 56-60 already cached.\n",
      "Batch 13: 61-65 already cached.\n",
      "Batch 14: 66-70 already cached.\n",
      "Batch 15: 71-75 already cached.\n",
      "Batch 16: 76-80 already cached.\n",
      "Batch 17: 81-85 already cached.\n",
      "Batch 18: 86-90 already cached.\n",
      "Batch 19: 91-95 already cached.\n",
      "Batch 20: 96-100 already cached.\n",
      "Batch 21: 101-105 already cached.\n",
      "Batch 22: 106-110 already cached.\n",
      "Batch 23: 111-115 already cached.\n",
      "Batch 24: 116-120 already cached.\n",
      "Batch 25: 121-125 already cached.\n",
      "Batch 26: 126-130 already cached.\n",
      "Batch 27: 131-135 already cached.\n",
      "Batch 28: 136-140 already cached.\n",
      "Batch 29: 141-145 already cached.\n",
      "Batch 30: 146-150 already cached.\n",
      "Batch 31: 151-155 already cached.\n",
      "Batch 32: 156-160 already cached.\n",
      "Batch 33: 161-165 already cached.\n",
      "Batch 34: 166-170 already cached.\n",
      "Batch 35: 171-175 already cached.\n",
      "Batch 36: 176-180 already cached.\n",
      "Batch 37: 181-185 already cached.\n",
      "Batch 38: 186-190 already cached.\n",
      "Batch 39: 191-195 already cached.\n",
      "Batch 40: 196-200 already cached.\n",
      "Batch 41: 201-205 already cached.\n",
      "Batch 42: 206-210 already cached.\n",
      "Batch 43: 211-215 already cached.\n",
      "Batch 44: 216-220 already cached.\n",
      "Batch 45: 221-225 already cached.\n",
      "Batch 46: 226-230 already cached.\n",
      "Batch 47: 231-235 already cached.\n",
      "Batch 48: 236-240 already cached.\n",
      "Batch 49: 241-245 already cached.\n",
      "Batch 50: 246-250 already cached.\n",
      "Batch 51: 251-255 already cached.\n",
      "Batch 52: 256-260 already cached.\n",
      "Batch 53: 261-265 already cached.\n",
      "Batch 54: 266-270 already cached.\n",
      "Batch 55: 271-275 already cached.\n",
      "Batch 56: 276-280 already cached.\n",
      "Batch 57: 281-285 already cached.\n",
      "Batch 58: 286-290 already cached.\n",
      "Batch 59: 291-295 already cached.\n",
      "Batch 60: 296-300 already cached.\n",
      "Batch 61: 301-305 already cached.\n",
      "Batch 62: 306-310 already cached.\n",
      "Batch 63: 311-315 already cached.\n",
      "Batch 64: 316-320 already cached.\n",
      "Batch 65: 321-325 already cached.\n",
      "Batch 66: 326-330 already cached.\n",
      "Batch 67: 331-335 already cached.\n",
      "Batch 68: 336-340 already cached.\n",
      "Batch 69: 341-345 already cached.\n",
      "Batch 70: 346-350 already cached.\n",
      "Batch 71: 351-355 already cached.\n",
      "Batch 72: 356-360 already cached.\n",
      "Batch 73: 361-365 already cached.\n",
      "Batch 74: 366-370 already cached.\n",
      "Batch 75: 371-375 already cached.\n",
      "Batch 76: 376-380 already cached.\n",
      "Fetching batch 77: facilities 381–385 (['SKSF', 'STHBKTEC', 'SVALE', 'STGEORGE', 'SLDCBLK'])\n",
      "HTTP 416: {\"version\":\"4.3.0\",\"response_status\":\"ERROR\",\"error\":\"No data available for facility ['SKSF', 'SLDCBLK', 'STHBKTEC', 'SVALE', 'STGEORGE'] in the speci\n",
      "Batch 78: 386-390 already cached.\n",
      "Batch 79: 391-395 already cached.\n",
      "Batch 80: 396-400 already cached.\n",
      "Batch 81: 401-405 already cached.\n",
      "Batch 82: 406-410 already cached.\n",
      "Batch 83: 411-415 already cached.\n",
      "Batch 84: 416-420 already cached.\n",
      "Batch 85: 421-425 already cached.\n",
      "Fetching batch 86: facilities 426–430 (['THEDROP', '0TILBSF', 'TIMWEST', '0TOMAGOBESS', 'TOORAWF'])\n",
      "HTTP 416: {\"version\":\"4.3.0\",\"response_status\":\"ERROR\",\"error\":\"No data available for facility ['TIMWEST', 'TOORAWF', '0TOMAGOBESS', '0TILBSF', 'THEDROP'] in th\n",
      "Batch 87: 431-435 already cached.\n",
      "Batch 88: 436-440 already cached.\n",
      "Batch 89: 441-445 already cached.\n",
      "Batch 90: 446-450 already cached.\n",
      "Batch 91: 451-455 already cached.\n",
      "Batch 92: 456-460 already cached.\n",
      "Batch 93: 461-465 already cached.\n",
      "Batch 94: 466-470 already cached.\n",
      "Batch 95: 471-475 already cached.\n",
      "Batch 96: 476-480 already cached.\n",
      "Batch 97: 481-485 already cached.\n",
      "Batch 98: 486-490 already cached.\n",
      "Batch 99: 491-495 already cached.\n",
      "Batch 100: 496-500 already cached.\n",
      "Batch 101: 501-505 already cached.\n",
      "Batch 102: 506-510 already cached.\n",
      "Batch 103: 511-514 already cached.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all facility data in batch of 5 per API call\n",
    "batch_retrieval(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> <span style=\"color:orange\">2. Data Integration and Caching</span></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some facilities have more than one units, so we need to make separate tables for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to separate the facilities and units rows\n",
    "def build_tables(facilities: list[dict]):\n",
    "    facility_rows: list[dict] = []\n",
    "    unit_rows: list[dict] = []\n",
    "\n",
    "    for f in facilities:\n",
    "        f_code = f.get(\"code\")\n",
    "        facility_rows.append({\n",
    "            \"facility_code\": f_code,\n",
    "            \"facility_name\": f.get(\"name\"),\n",
    "            \"network_id\": f.get(\"network_id\"),\n",
    "            \"network_region\": f.get(\"network_region\"),\n",
    "            \"lat\": (f.get(\"location\") or {}).get(\"lat\"),\n",
    "            \"lng\": (f.get(\"location\") or {}).get(\"lng\"),\n",
    "            \"created_at\": f.get(\"created_at\"),\n",
    "            \"updated_at\": f.get(\"updated_at\"),\n",
    "        })\n",
    "\n",
    "        for u in (f.get(\"units\") or []):\n",
    "                # unify field names we care about\n",
    "                unit_rows.append({\n",
    "                    \"unit_code\": u.get(\"code\"),\n",
    "                    \"facility_code\": f_code,\n",
    "                    \"fueltech_id\": u.get(\"fueltech_id\"),\n",
    "                    \"status_id\": u.get(\"status_id\"),\n",
    "                    \"dispatch_type\": u.get(\"dispatch_type\"),\n",
    "                    \"capacity_registered\": u.get(\"capacity_registered\"),\n",
    "                    \"capacity_maximum\": u.get(\"capacity_maximum\"),\n",
    "                    \"capacity_storage\": u.get(\"capacity_storage\"),\n",
    "                    \"data_first_seen\": u.get(\"data_first_seen\"),\n",
    "                    \"data_last_seen\": u.get(\"data_last_seen\"),\n",
    "                    \"unit_created_at\": u.get(\"created_at\"),\n",
    "                    \"unit_updated_at\": u.get(\"updated_at\"),\n",
    "                })\n",
    "    \n",
    "    facilities_df = pd.DataFrame(facility_rows).drop_duplicates(subset=[\"facility_code\"]).reset_index(drop=True)\n",
    "    units_lookup_df = pd.DataFrame(unit_rows).drop_duplicates(subset=[\"unit_code\"]).reset_index(drop=True)\n",
    "\n",
    "    return facilities_df, units_lookup_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tables into separate csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: DATA\\EXTRACTED\\electricity_facilities.csv\n",
      "Saved: DATA\\EXTRACTED\\electricity_units_facilities.csv\n"
     ]
    }
   ],
   "source": [
    "facilities_df, units_facilities_df = build_tables(facilities['data'])\n",
    "\n",
    "# save to csv\n",
    "save_dataset(facilities_df, \"DATA/EXTRACTED/electricity_facilities.csv\")\n",
    "save_dataset(units_facilities_df, \"DATA/EXTRACTED/electricity_units_facilities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For power and emission data per facility, we need to perform some pre-processing to store them into a cached csv file. Specifically, for this process we need to:\n",
    "1. Combine all cached .json data of into one dataframe.\n",
    "2. Sum the facilitiy data to get total power and emissions per facility (some facilities have more than one units).\n",
    "3. Append additional information to each facility (e.g. lat, lon, facility_name, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all json cache into one dataframe\n",
    "records = []\n",
    "for path in glob.glob(\"./DATA/EXTRACTED/*.json\"):\n",
    "    payload = json.load(open(path))\n",
    "    \n",
    "    records.extend(flatten(payload))\n",
    "\n",
    "series_df = pd.DataFrame(records)\n",
    "\n",
    "lookup = pd.read_csv(\"./DATA/EXTRACTED/electricity_units_facilities.csv\")[[\"unit_code\",\"facility_code\"]]\n",
    "series_df = series_df.merge(lookup, on=\"unit_code\", how=\"left\")\n",
    "facility_df = (series_df.groupby([\"timestamp\",\"facility_code\",\"metric\"], as_index=False)[\"value\"].sum())\n",
    "\n",
    "facilities_df = pd.read_csv(\"./DATA/EXTRACTED/electricity_facilities.csv\")[\n",
    "    [\"facility_code\", \"facility_name\", \"network_id\", \"network_region\", \"lat\", \"lng\"]\n",
    "]\n",
    "facility_df = facility_df.merge(facilities_df, on=\"facility_code\", how=\"left\")\n",
    "\n",
    "# reorder columns for clarity\n",
    "facility_df = facility_df[\n",
    "    [\n",
    "        \"timestamp\", \"facility_code\", \"facility_name\", \"network_id\", \"network_region\",\n",
    "        \"lat\", \"lng\", \"metric\", \"value\"\n",
    "    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: DATA\\EXTRACTED\\consolidated_facilities.csv\n"
     ]
    }
   ],
   "source": [
    "# save to csv\n",
    "save_dataset(facility_df, \"DATA/EXTRACTED/consolidated_facilities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>facility_code</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>network_id</th>\n",
       "      <th>network_region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01T00:00:00+10:00</td>\n",
       "      <td>0MREH</td>\n",
       "      <td>Melbourne A1</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.661274</td>\n",
       "      <td>144.726302</td>\n",
       "      <td>emissions</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-01T00:00:00+10:00</td>\n",
       "      <td>0MREH</td>\n",
       "      <td>Melbourne A1</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.661274</td>\n",
       "      <td>144.726302</td>\n",
       "      <td>power</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-01T00:00:00+10:00</td>\n",
       "      <td>0MREHA2</td>\n",
       "      <td>Melbourne A2</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.663934</td>\n",
       "      <td>144.726927</td>\n",
       "      <td>emissions</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-01T00:00:00+10:00</td>\n",
       "      <td>0MREHA2</td>\n",
       "      <td>Melbourne A2</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.663934</td>\n",
       "      <td>144.726927</td>\n",
       "      <td>power</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-01T00:00:00+10:00</td>\n",
       "      <td>0TARONGBESS</td>\n",
       "      <td>Tarong</td>\n",
       "      <td>NEM</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-26.780051</td>\n",
       "      <td>151.912068</td>\n",
       "      <td>emissions</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336701</th>\n",
       "      <td>2025-10-07T23:55:00+10:00</td>\n",
       "      <td>YATSF1</td>\n",
       "      <td>Yatpool</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-34.380730</td>\n",
       "      <td>142.205340</td>\n",
       "      <td>power</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336702</th>\n",
       "      <td>2025-10-07T23:55:00+10:00</td>\n",
       "      <td>YENDONWF</td>\n",
       "      <td>Yendon</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.630952</td>\n",
       "      <td>144.022463</td>\n",
       "      <td>emissions</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336703</th>\n",
       "      <td>2025-10-07T23:55:00+10:00</td>\n",
       "      <td>YENDONWF</td>\n",
       "      <td>Yendon</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.630952</td>\n",
       "      <td>144.022463</td>\n",
       "      <td>power</td>\n",
       "      <td>89.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336704</th>\n",
       "      <td>2025-10-07T23:55:00+10:00</td>\n",
       "      <td>YSWF</td>\n",
       "      <td>Yaloak South</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.716474</td>\n",
       "      <td>144.241947</td>\n",
       "      <td>emissions</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336705</th>\n",
       "      <td>2025-10-07T23:55:00+10:00</td>\n",
       "      <td>YSWF</td>\n",
       "      <td>Yaloak South</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.716474</td>\n",
       "      <td>144.241947</td>\n",
       "      <td>power</td>\n",
       "      <td>11.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1336706 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp facility_code facility_name network_id  \\\n",
       "0        2025-10-01T00:00:00+10:00         0MREH  Melbourne A1        NEM   \n",
       "1        2025-10-01T00:00:00+10:00         0MREH  Melbourne A1        NEM   \n",
       "2        2025-10-01T00:00:00+10:00       0MREHA2  Melbourne A2        NEM   \n",
       "3        2025-10-01T00:00:00+10:00       0MREHA2  Melbourne A2        NEM   \n",
       "4        2025-10-01T00:00:00+10:00   0TARONGBESS        Tarong        NEM   \n",
       "...                            ...           ...           ...        ...   \n",
       "1336701  2025-10-07T23:55:00+10:00        YATSF1       Yatpool        NEM   \n",
       "1336702  2025-10-07T23:55:00+10:00      YENDONWF        Yendon        NEM   \n",
       "1336703  2025-10-07T23:55:00+10:00      YENDONWF        Yendon        NEM   \n",
       "1336704  2025-10-07T23:55:00+10:00          YSWF  Yaloak South        NEM   \n",
       "1336705  2025-10-07T23:55:00+10:00          YSWF  Yaloak South        NEM   \n",
       "\n",
       "        network_region        lat         lng     metric  value  \n",
       "0                 VIC1 -37.661274  144.726302  emissions   0.00  \n",
       "1                 VIC1 -37.661274  144.726302      power   0.00  \n",
       "2                 VIC1 -37.663934  144.726927  emissions   0.00  \n",
       "3                 VIC1 -37.663934  144.726927      power   0.00  \n",
       "4                 QLD1 -26.780051  151.912068  emissions   0.00  \n",
       "...                ...        ...         ...        ...    ...  \n",
       "1336701           VIC1 -34.380730  142.205340      power   0.00  \n",
       "1336702           VIC1 -37.630952  144.022463  emissions   0.00  \n",
       "1336703           VIC1 -37.630952  144.022463      power  89.87  \n",
       "1336704           VIC1 -37.716474  144.241947  emissions   0.00  \n",
       "1336705           VIC1 -37.716474  144.241947      power  11.60  \n",
       "\n",
       "[1336706 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"DATA/EXTRACTED/consolidated_facilities.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = (\n",
    "    df\n",
    "    .pivot_table(\n",
    "        index=[\n",
    "            \"timestamp\", \"facility_code\", \"facility_name\",\n",
    "            \"network_id\", \"network_region\", \"lat\", \"lng\"\n",
    "        ],\n",
    "        columns=\"metric\",\n",
    "        values=\"value\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pivot_df.columns.name = None  # remove 'metric' label\n",
    "pivot_df = pivot_df.rename_axis(None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp         datetime64[ns, UTC+10:00]\n",
       "facility_code                        object\n",
       "facility_name                        object\n",
       "network_id                           object\n",
       "network_region                       object\n",
       "lat                                 float64\n",
       "lng                                 float64\n",
       "emissions                           float64\n",
       "power                               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df[\"timestamp\"] = pd.to_datetime(pivot_df[\"timestamp\"])\n",
    "pivot_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>facility_code</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>network_id</th>\n",
       "      <th>network_region</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>emissions</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01 00:00:00+10:00</td>\n",
       "      <td>0MREH</td>\n",
       "      <td>Melbourne A1</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.661274</td>\n",
       "      <td>144.726302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-01 00:00:00+10:00</td>\n",
       "      <td>0MREHA2</td>\n",
       "      <td>Melbourne A2</td>\n",
       "      <td>NEM</td>\n",
       "      <td>VIC1</td>\n",
       "      <td>-37.663934</td>\n",
       "      <td>144.726927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-01 00:00:00+10:00</td>\n",
       "      <td>0TARONGBESS</td>\n",
       "      <td>Tarong</td>\n",
       "      <td>NEM</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-26.780051</td>\n",
       "      <td>151.912068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-01 00:00:00+10:00</td>\n",
       "      <td>0WAMBOWF</td>\n",
       "      <td>Wambo</td>\n",
       "      <td>NEM</td>\n",
       "      <td>QLD1</td>\n",
       "      <td>-26.603045</td>\n",
       "      <td>151.246876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-01 00:00:00+10:00</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Adelaide Desalination</td>\n",
       "      <td>NEM</td>\n",
       "      <td>SA1</td>\n",
       "      <td>-35.096948</td>\n",
       "      <td>138.484061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp facility_code          facility_name network_id  \\\n",
       "0 2025-10-01 00:00:00+10:00         0MREH           Melbourne A1        NEM   \n",
       "1 2025-10-01 00:00:00+10:00       0MREHA2           Melbourne A2        NEM   \n",
       "2 2025-10-01 00:00:00+10:00   0TARONGBESS                 Tarong        NEM   \n",
       "3 2025-10-01 00:00:00+10:00      0WAMBOWF                  Wambo        NEM   \n",
       "4 2025-10-01 00:00:00+10:00           ADP  Adelaide Desalination        NEM   \n",
       "\n",
       "  network_region        lat         lng  emissions  power  \n",
       "0           VIC1 -37.661274  144.726302        0.0   0.00  \n",
       "1           VIC1 -37.663934  144.726927        0.0   0.00  \n",
       "2           QLD1 -26.780051  151.912068        0.0   0.00  \n",
       "3           QLD1 -26.603045  151.246876        0.0  65.23  \n",
       "4            SA1 -35.096948  138.484061        0.0   0.00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: DATA\\EXTRACTED\\consolidated_facilities_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# save to csv\n",
    "save_dataset(pivot_df, \"DATA/EXTRACTED/consolidated_facilities_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'facility_code', 'facility_name', 'network_id',\n",
       "       'network_region', 'lat', 'lng', 'emissions', 'power'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> <span style=\"color:orange\">3. Data Publishing via MTQQ</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtqq_publisher as publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to publish 668353 records...\n",
      "[PUBLISHED] 0MREH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PORTLCN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PIONEER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PIBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PAREPW @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PALOONA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OSBORNE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OAKLAND @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PORTWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OAKEY2SF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OAKEY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NYNGAN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NUMURKSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NPPPPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NEWPORT @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NEWENSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NEVERSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OAKEY1SF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] PTINA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] QBYNB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SAPHWF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SALTCRK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RYEPARK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RYANCWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RUGBYR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RUBICON @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RRSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RPCG @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ROYALLA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ROWALLAN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ROMA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RIVNB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] REPULSE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] REECE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] RANGEB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] QUARANTN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] NBHWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MWPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MUWAWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MUSSELRO @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] METZSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MEADOWBK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MCKAY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MCINTYR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MBPS2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MBAHNTH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MARYRSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MAPS2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MANSLR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MANNUMB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MANNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MACKNTSH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MACARTH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LRSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LOYYB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LOYYANGA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LONSDALE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MEWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SHOAL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MIDDLSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MINTARO @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MURRAY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MUCRKSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MTMILLAR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MTMERCER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MTGELWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MSTUART @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MRTLSWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MREHA3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MOUSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MORTLK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MOREESF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MOORAWF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MOLNGSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MOKOSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MLSP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] MILLMERN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LNGS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SHOALHAV @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SMCSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WKIEWA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WIVENHOE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WINTSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WHITSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WGWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WEMENSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WELNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WLWLSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WELLSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WDBESS2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WDBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WAUBRAWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WATERLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WARWSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WANDSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WANDBG @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WDGPH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WOLARSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WOODLWN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YSWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YENDONWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YATSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YARWUN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YARANSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YAMBUK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YALLOURN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] YABULU @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WYASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WUNUSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WTAHB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WSTWYSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WRWF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WRSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WPWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WOOLNTH1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WOOLGSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WALGRV @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] WAGGNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] VPGS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] VP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SUNRSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] STWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] STOCKYD @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] STARFHILL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] STANWELL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] STANVAC @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SRSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNUG @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWY6 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWY3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWY2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWTOWN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWSTH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNOWNTH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNB1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SNAPPER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SMTHBES1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SUNTPSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SITHE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SWAN_E @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TALWB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] VBB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] URANQ @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ULBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TVCCPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TUNGATIN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TUMUT3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TULLYSM @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TRIBUTE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TREVALLN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TORRIS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TIB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TBSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TB2SF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TARRALEA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TARONGN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TARONG @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TARALGA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] TALLAWAR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LK_ECHO @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] SEBSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LKBONNY3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLEMGPWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLARESF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CHYTWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CHILDSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CHBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CHALLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CETHANA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLERMSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CBWWBA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CAPTL_WF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CAPBES @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CANUNDA1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CALL_B @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CALLIDEC1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BWTR1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BUTLERSG @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CATHROCK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLOVER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLRKCWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CLUNY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DALNTH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CULLERIN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CTHLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CSPVPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CRWASF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CRURWF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CROWLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CROOKWF3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CROOKWF2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CPSA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COOPGWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] CONDONG1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COLWF01 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COLUMSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COLONGRA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COLEASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] COHUNSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BULGANA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BRYB1WF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BROKENH @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BRNDBES @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BARKIPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BARCSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BARCALDN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BANNSP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BANGOWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BALBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] B2PS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] AVLSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ARWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ANGASTON @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ALDGASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] AGLSOM @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] AGLHAL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ADP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] 0WAMBOWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] 0TARONGBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LKBONNY_2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BARRON @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DARLSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BASTYAN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BBATTERY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BRAEMARA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BOMENSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BOLIVPS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BOLIVAR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BODWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BOCOROCK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BNGSF2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BNGSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BLYTHB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BLUFF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BLUEGSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BIALAWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BHWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BHILLGT @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BHB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BERYLSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BBP31 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] BAYSW @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DARTM @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] 0MREHA2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DDPS1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] JEMALNG1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] JEERB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] JEERA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] JBUTTERS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HVWW @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HUNTER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HUMEV @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HUMENSW @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HUGSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HORNSDPR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HORNSDAL3 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HORNSDAL2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HORNSDAL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HILLSTN @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HEZ @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HD1WF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] JUNEESF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HAYMSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KABANWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KARSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DAYDSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LI_WY_CA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LIMOSF2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LIMOSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LILYVASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LGAPWF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LEM_WIL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LBBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LADBROKE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KSP1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KOGANCK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KINGASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KIATAWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KIAMSF1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KESS1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KERNGSP @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KENNEDY @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] KAREEYA @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HAUGHT1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] LKBONNY1 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HALLWF2 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] FINLEYSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ERGT01 @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ERB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ERARING @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] EMERASF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] ELAINEWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] EDENVSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] FISHER @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DUNDWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DRYCGT @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DPNTB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DIAPURWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DEVILS_G @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DEIBDL @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DDSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HAMISF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] DULAWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] FLYCRKWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] EILDON @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GANNBESS @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GANGARR @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GUNNING @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GULLRGWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GSWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GSTONE @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GRIFSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GRANWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GPWFEST @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GREENB @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] HALLWF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GOONUMSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GNNDHSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GLRWNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GLENSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GIRGSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GERMCRK @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GANNSF @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] GORDON @ 2025-10-01 00:00:00+10:00\n",
      "[PUBLISHED] OSBORNE @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PORTLCN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PIONEER @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PIBESS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PAREPW @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PALOONA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] OAKLAND @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NEVERSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] OAKEY1SF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] OAKEY @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NYNGAN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NUMURKSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NPPPPS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NEWPORT @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NEWENSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PORTWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] OAKEY2SF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SAPHWF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] QBYNB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] LONSDALE @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SALTCRK @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RYEPARK @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RYANCWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RUGBYR @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RUBICON @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RRSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RPCG @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] ROYALLA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] ROWALLAN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] ROMA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RIVNB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RESS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] REPULSE @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] REECE @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] RANGEB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] QUARANTN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] PTINA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] NBHWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MLSP @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MUWAWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] METZSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MEADOWBK @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MCKAY @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MCINTYR @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MBPS2 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MBAHNTH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MARYRSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MAPS2 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MANSLR @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MANNUMB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MANNSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MACKNTSH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MACARTH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] LRSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] LOYYB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] LOYYANGA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SHOAL @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MEWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MWPS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MIDDLSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MINTARO @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MUSSELRO @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MURRAY @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MUCRKSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MTMILLAR @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MTMERCER @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MTGELWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MSTUART @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MRTLSWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MREHA3 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MP @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MOUSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MORTLK @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MOREESF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MOORAWF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MOLNGSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MOKOSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MLWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] MILLMERN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SHOALHAV @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] VBB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SMCSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WLWLSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WKIEWA @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WIVENHOE @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WINTSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WHITSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WGWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WEMENSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WNSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WELNSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WDGPH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WDBESS2 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WDBESS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WAUBRAWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WATERLWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WARWSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WANDSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WELLSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WOLARSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WOODLWN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WOOLGSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] LNGS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YSWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YENDONWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YATSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YARWUN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YARANSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YAMBUK @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YALLOURN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] YABULU @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WYASF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WUNUSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WTAHB @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WSTWYSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WRWF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WRSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WPWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WOOLNTH1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WANDBG @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WALGRV @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] WAGGNSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] VPGS @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SUNRSF1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] STWF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] STOCKYD @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] STARFHILL @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] STANWELL @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] STANVAC @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SRSF @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNUG @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWY6 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWY3 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWY2 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWTOWN @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWSTH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNOWNTH @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNB1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SNAPPER @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SMTHBES1 @ 2025-10-01 00:05:00+10:00\n",
      "[PUBLISHED] SUNTPSF @ 2025-10-01 00:05:00+10:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mDATA/EXTRACTED/consolidated_facilities_cleaned.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m publisher.initialise_mqtt_client()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mpublisher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpublish_data_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m publisher.stop_mtqq_client()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Rengga\\venv\\DE\\Assignment 2_Tut07_G04\\mtqq_publisher.py:57\u001b[39m, in \u001b[36mpublish_data_stream\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     54\u001b[39m client.publish(TOPIC, message)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[PUBLISHED] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mfacility_code\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"DATA/EXTRACTED/consolidated_facilities_cleaned.csv\")\n",
    "\n",
    "publisher.initialise_mqtt_client()\n",
    "publisher.publish_data_stream(df)\n",
    "publisher.stop_mtqq_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> <span style=\"color:orange\">4. Dashboard and Visualisation</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected with result code Success\n",
      "Ready to publish to topic: COMP5339/T07G04/facilities\n"
     ]
    }
   ],
   "source": [
    "import mtqq_publisher as publisher"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_assignment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
